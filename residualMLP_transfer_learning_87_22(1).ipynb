{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "zEgbg5Sez64n",
        "outputId": "093bfe06-2994-4885-e658-9cc87c5cf083"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python version: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "pandas 2.2.2 sklearn 1.6.1\n",
            "Training CSV exists: True\n",
            "Feature description exists: True\n",
            "Training data shape: (175341, 45)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   ï»¿id       dur proto service state  spkts  dpkts  sbytes  dbytes  \\\n",
              "0      1  0.121478   tcp       -   FIN      6      4     258     172   \n",
              "1      2  0.649902   tcp       -   FIN     14     38     734   42014   \n",
              "2      3  1.623129   tcp       -   FIN      8     16     364   13186   \n",
              "3      4  1.681642   tcp     ftp   FIN     12     12     628     770   \n",
              "4      5  0.449454   tcp       -   FIN     10      6     534     268   \n",
              "5      6  0.380537   tcp       -   FIN     10      6     534     268   \n",
              "6      7  0.637109   tcp       -   FIN     10      8     534     354   \n",
              "7      8  0.521584   tcp       -   FIN     10      8     534     354   \n",
              "8      9  0.542905   tcp       -   FIN     10      8     534     354   \n",
              "9     10  0.258687   tcp       -   FIN     10      6     534     268   \n",
              "\n",
              "        rate  ...  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  ct_ftp_cmd  \\\n",
              "0  74.087490  ...                 1               1             0           0   \n",
              "1  78.473372  ...                 1               2             0           0   \n",
              "2  14.170161  ...                 1               3             0           0   \n",
              "3  13.677108  ...                 1               3             1           1   \n",
              "4  33.373826  ...                 1              40             0           0   \n",
              "5  39.417980  ...                 1              40             0           0   \n",
              "6  26.683033  ...                 1              40             0           0   \n",
              "7  32.593026  ...                 1              40             0           0   \n",
              "8  31.313031  ...                 1              40             0           0   \n",
              "9  57.985135  ...                 1              40             0           0   \n",
              "\n",
              "   ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  attack_cat  \\\n",
              "0                 0           1           1                0      Normal   \n",
              "1                 0           1           6                0      Normal   \n",
              "2                 0           2           6                0      Normal   \n",
              "3                 0           2           1                0      Normal   \n",
              "4                 0           2          39                0      Normal   \n",
              "5                 0           2          39                0      Normal   \n",
              "6                 0           1          39                0      Normal   \n",
              "7                 0           3          39                0      Normal   \n",
              "8                 0           3          39                0      Normal   \n",
              "9                 0           3          39                0      Normal   \n",
              "\n",
              "   label  \n",
              "0      0  \n",
              "1      0  \n",
              "2      0  \n",
              "3      0  \n",
              "4      0  \n",
              "5      0  \n",
              "6      0  \n",
              "7      0  \n",
              "8      0  \n",
              "9      0  \n",
              "\n",
              "[10 rows x 45 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-17eb033b-284e-4ebc-9a50-71149781463c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ï»¿id</th>\n",
              "      <th>dur</th>\n",
              "      <th>proto</th>\n",
              "      <th>service</th>\n",
              "      <th>state</th>\n",
              "      <th>spkts</th>\n",
              "      <th>dpkts</th>\n",
              "      <th>sbytes</th>\n",
              "      <th>dbytes</th>\n",
              "      <th>rate</th>\n",
              "      <th>...</th>\n",
              "      <th>ct_dst_sport_ltm</th>\n",
              "      <th>ct_dst_src_ltm</th>\n",
              "      <th>is_ftp_login</th>\n",
              "      <th>ct_ftp_cmd</th>\n",
              "      <th>ct_flw_http_mthd</th>\n",
              "      <th>ct_src_ltm</th>\n",
              "      <th>ct_srv_dst</th>\n",
              "      <th>is_sm_ips_ports</th>\n",
              "      <th>attack_cat</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.121478</td>\n",
              "      <td>tcp</td>\n",
              "      <td>-</td>\n",
              "      <td>FIN</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>258</td>\n",
              "      <td>172</td>\n",
              "      <td>74.087490</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.649902</td>\n",
              "      <td>tcp</td>\n",
              "      <td>-</td>\n",
              "      <td>FIN</td>\n",
              "      <td>14</td>\n",
              "      <td>38</td>\n",
              "      <td>734</td>\n",
              "      <td>42014</td>\n",
              "      <td>78.473372</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1.623129</td>\n",
              "      <td>tcp</td>\n",
              "      <td>-</td>\n",
              "      <td>FIN</td>\n",
              "      <td>8</td>\n",
              "      <td>16</td>\n",
              "      <td>364</td>\n",
              "      <td>13186</td>\n",
              "      <td>14.170161</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1.681642</td>\n",
              "      <td>tcp</td>\n",
              "      <td>ftp</td>\n",
              "      <td>FIN</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>628</td>\n",
              "      <td>770</td>\n",
              "      <td>13.677108</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.449454</td>\n",
              "      <td>tcp</td>\n",
              "      <td>-</td>\n",
              "      <td>FIN</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>534</td>\n",
              "      <td>268</td>\n",
              "      <td>33.373826</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>0.380537</td>\n",
              "      <td>tcp</td>\n",
              "      <td>-</td>\n",
              "      <td>FIN</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>534</td>\n",
              "      <td>268</td>\n",
              "      <td>39.417980</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>0.637109</td>\n",
              "      <td>tcp</td>\n",
              "      <td>-</td>\n",
              "      <td>FIN</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>534</td>\n",
              "      <td>354</td>\n",
              "      <td>26.683033</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>0.521584</td>\n",
              "      <td>tcp</td>\n",
              "      <td>-</td>\n",
              "      <td>FIN</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>534</td>\n",
              "      <td>354</td>\n",
              "      <td>32.593026</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>0.542905</td>\n",
              "      <td>tcp</td>\n",
              "      <td>-</td>\n",
              "      <td>FIN</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>534</td>\n",
              "      <td>354</td>\n",
              "      <td>31.313031</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>0.258687</td>\n",
              "      <td>tcp</td>\n",
              "      <td>-</td>\n",
              "      <td>FIN</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>534</td>\n",
              "      <td>268</td>\n",
              "      <td>57.985135</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 45 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17eb033b-284e-4ebc-9a50-71149781463c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-17eb033b-284e-4ebc-9a50-71149781463c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-17eb033b-284e-4ebc-9a50-71149781463c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-58afbafc-e978-479b-a3ba-e92c0324fd84\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-58afbafc-e978-479b-a3ba-e92c0324fd84')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-58afbafc-e978-479b-a3ba-e92c0324fd84 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---\n",
            "Feature description preview:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    No.     Name    Type                                         Description\n",
              "0     1    srcip  nominal                                  Source IP address\n",
              "1     2    sport  integer                                 Source port number\n",
              "2     3    dstip  nominal                             Destination IP address\n",
              "3     4   dsport  integer                            Destination port number\n",
              "4     5    proto  nominal                               Transaction protocol\n",
              "5     6    state  nominal  Indicates to the state and its dependent proto...\n",
              "6     7      dur    Float                              Record total duration\n",
              "7     8   sbytes  Integer           Source to destination transaction bytes \n",
              "8     9   dbytes  Integer            Destination to source transaction bytes\n",
              "9    10     sttl  Integer          Source to destination time to live value \n",
              "10   11     dttl  Integer           Destination to source time to live value\n",
              "11   12    sloss  Integer           Source packets retransmitted or dropped \n",
              "12   13    dloss  Integer       Destination packets retransmitted or dropped\n",
              "13   14  service  nominal  http, ftp, smtp, ssh, dns, ftp-data ,irc  and ...\n",
              "14   15    Sload    Float                             Source bits per second\n",
              "15   16    Dload    Float                        Destination bits per second\n",
              "16   17    Spkts  integer                Source to destination packet count \n",
              "17   18    Dpkts  integer                 Destination to source packet count\n",
              "18   19     swin  integer              Source TCP window advertisement value\n",
              "19   20     dwin  integer         Destination TCP window advertisement value"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ce127831-5a90-432a-915e-afd26efe45cc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>No.</th>\n",
              "      <th>Name</th>\n",
              "      <th>Type</th>\n",
              "      <th>Description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>srcip</td>\n",
              "      <td>nominal</td>\n",
              "      <td>Source IP address</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>sport</td>\n",
              "      <td>integer</td>\n",
              "      <td>Source port number</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>dstip</td>\n",
              "      <td>nominal</td>\n",
              "      <td>Destination IP address</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>dsport</td>\n",
              "      <td>integer</td>\n",
              "      <td>Destination port number</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>proto</td>\n",
              "      <td>nominal</td>\n",
              "      <td>Transaction protocol</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>state</td>\n",
              "      <td>nominal</td>\n",
              "      <td>Indicates to the state and its dependent proto...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>dur</td>\n",
              "      <td>Float</td>\n",
              "      <td>Record total duration</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>sbytes</td>\n",
              "      <td>Integer</td>\n",
              "      <td>Source to destination transaction bytes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>dbytes</td>\n",
              "      <td>Integer</td>\n",
              "      <td>Destination to source transaction bytes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>sttl</td>\n",
              "      <td>Integer</td>\n",
              "      <td>Source to destination time to live value</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>dttl</td>\n",
              "      <td>Integer</td>\n",
              "      <td>Destination to source time to live value</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>sloss</td>\n",
              "      <td>Integer</td>\n",
              "      <td>Source packets retransmitted or dropped</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>dloss</td>\n",
              "      <td>Integer</td>\n",
              "      <td>Destination packets retransmitted or dropped</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>service</td>\n",
              "      <td>nominal</td>\n",
              "      <td>http, ftp, smtp, ssh, dns, ftp-data ,irc  and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>Sload</td>\n",
              "      <td>Float</td>\n",
              "      <td>Source bits per second</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>16</td>\n",
              "      <td>Dload</td>\n",
              "      <td>Float</td>\n",
              "      <td>Destination bits per second</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>17</td>\n",
              "      <td>Spkts</td>\n",
              "      <td>integer</td>\n",
              "      <td>Source to destination packet count</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18</td>\n",
              "      <td>Dpkts</td>\n",
              "      <td>integer</td>\n",
              "      <td>Destination to source packet count</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>19</td>\n",
              "      <td>swin</td>\n",
              "      <td>integer</td>\n",
              "      <td>Source TCP window advertisement value</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>20</td>\n",
              "      <td>dwin</td>\n",
              "      <td>integer</td>\n",
              "      <td>Destination TCP window advertisement value</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce127831-5a90-432a-915e-afd26efe45cc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ce127831-5a90-432a-915e-afd26efe45cc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ce127831-5a90-432a-915e-afd26efe45cc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0dddfb84-c005-417e-8c7f-396d68f5221b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0dddfb84-c005-417e-8c7f-396d68f5221b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0dddfb84-c005-417e-8c7f-396d68f5221b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(feat\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"No.\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 1,\n        \"max\": 20,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          1,\n          18,\n          16\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"srcip\",\n          \"Dpkts\",\n          \"Dload\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Type \",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"integer\",\n          \"Integer\",\n          \"nominal\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"Source IP address\",\n          \"Destination to source packet count\",\n          \"Destination bits per second\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Imports and file paths\n",
        "import sys\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import os\n",
        "import json\n",
        "print('Python version:', sys.version)\n",
        "\n",
        "# Standard data science libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# sklearn & joblib will be used\n",
        "import sklearn\n",
        "import joblib\n",
        "print('pandas', pd.__version__, 'sklearn', sklearn.__version__)\n",
        "\n",
        "# Paths (these files were uploaded in this session)\n",
        "TRAIN_CSV = \"/content/SENG_4610_Training_Data.csv\"\n",
        "FEATURES_CSV = \"/content/Feature_Description.csv\"\n",
        "\n",
        "# Check files\n",
        "print('Training CSV exists:', Path(TRAIN_CSV).exists())\n",
        "print('Feature description exists:', Path(FEATURES_CSV).exists())\n",
        "\n",
        "# Load CSVs\n",
        "df = pd.read_csv(TRAIN_CSV, encoding='latin-1')\n",
        "feat = pd.read_csv(FEATURES_CSV, encoding='latin-1')\n",
        "\n",
        "print('Training data shape:', df.shape)\n",
        "display(df.head(10))\n",
        "print('\\n---\\nFeature description preview:')\n",
        "display(feat.head(20))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick EDA\n",
        "print('Columns:', df.columns.tolist())\n",
        "print('\\nDtypes:\\n', df.dtypes.value_counts())\n",
        "\n",
        "# Missing values summary\n",
        "missing = df.isna().sum().sort_values(ascending=False)\n",
        "display(missing.head(30))\n",
        "\n",
        "# Confirm target column names (adjust if different)\n",
        "possible_label_cols = ['label', 'Label', 'attack', 'is_attack']\n",
        "possible_attack_cat = ['attack_cat', 'attack_catagory', 'attack_category', 'attack_type']\n",
        "\n",
        "print('Columns present that match common names:')\n",
        "print([c for c in df.columns if c in possible_label_cols])\n",
        "print([c for c in df.columns if c in possible_attack_cat])\n",
        "\n",
        "# If your dataset uses different names, update these variables:\n",
        "BINARY_TARGET = 'label'           # 0 normal, 1 attack\n",
        "MULTI_TARGET = 'attack_cat'       # multiclass attack category\n",
        "ID_COL = 'id'"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "kfKQJDcPz9ns",
        "outputId": "e8acc0f6-0f35-48e8-8f0b-b8d038234df2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns: ['ï»¿id', 'dur', 'proto', 'service', 'state', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'rate', 'sttl', 'dttl', 'sload', 'dload', 'sloss', 'dloss', 'sinpkt', 'dinpkt', 'sjit', 'djit', 'swin', 'stcpb', 'dtcpb', 'dwin', 'tcprtt', 'synack', 'ackdat', 'smean', 'dmean', 'trans_depth', 'response_body_len', 'ct_srv_src', 'ct_state_ttl', 'ct_dst_ltm', 'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'is_ftp_login', 'ct_ftp_cmd', 'ct_flw_http_mthd', 'ct_src_ltm', 'ct_srv_dst', 'is_sm_ips_ports', 'attack_cat', 'label']\n",
            "\n",
            "Dtypes:\n",
            " int64      30\n",
            "float64    11\n",
            "object      4\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ï»¿id          0\n",
              "dur            0\n",
              "proto          0\n",
              "service        0\n",
              "state          0\n",
              "spkts          0\n",
              "dpkts          0\n",
              "sbytes         0\n",
              "dbytes         0\n",
              "rate           0\n",
              "sttl           0\n",
              "dttl           0\n",
              "sload          0\n",
              "dload          0\n",
              "sloss          0\n",
              "dloss          0\n",
              "sinpkt         0\n",
              "dinpkt         0\n",
              "sjit           0\n",
              "djit           0\n",
              "swin           0\n",
              "stcpb          0\n",
              "dtcpb          0\n",
              "dwin           0\n",
              "tcprtt         0\n",
              "synack         0\n",
              "ackdat         0\n",
              "smean          0\n",
              "dmean          0\n",
              "trans_depth    0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ï»¿id</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dur</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>proto</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>service</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>state</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>spkts</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dpkts</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sbytes</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dbytes</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rate</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sttl</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dttl</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sload</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dload</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sloss</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dloss</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sinpkt</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dinpkt</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sjit</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>djit</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>swin</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>stcpb</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dtcpb</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dwin</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tcprtt</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>synack</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ackdat</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>smean</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dmean</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>trans_depth</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns present that match common names:\n",
            "['label']\n",
            "['attack_cat']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop ID if present\n",
        "if ID_COL in df.columns:\n",
        "    df = df.drop(columns=[ID_COL])\n",
        "    print('Dropped id column')\n",
        "\n",
        "# Clean service & other textual columns\n",
        "for col in ['service', 'proto', 'state']:\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].astype(str)\n",
        "        df[col] = df[col].replace(['-', '?', 'None', 'nan', ''], 'unknown')\n",
        "        df[col] = df[col].fillna('unknown')\n",
        "\n",
        "# Show unique counts\n",
        "for col in ['service', 'proto', 'state']:\n",
        "    if col in df.columns:\n",
        "        print(f\"-> {col}: unique count =\", df[col].nunique(), 'example values =', df[col].unique()[:10])\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Ensure binary target is numeric 0/1\n",
        "if df[BINARY_TARGET].dtype == object:\n",
        "    # if the label is text like 'Normal'/'Attack' or 'normal'/'anomaly'\n",
        "    df['is_attack'] = df[BINARY_TARGET].str.lower().isin(\n",
        "        ['1', 'attack', 'anomaly', 'attack!', 'attack?']\n",
        "    ).astype(int)\n",
        "else:\n",
        "    df['is_attack'] = df[BINARY_TARGET].astype(int)\n",
        "\n",
        "print('is_attack distribution:')\n",
        "print(df['is_attack'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "oe-5vSOkz9qV",
        "outputId": "84293a66-ecf4-49ad-a472-1fd944c44de5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-> service: unique count = 13 example values = ['unknown' 'ftp' 'smtp' 'snmp' 'http' 'ftp-data' 'dns' 'ssh' 'radius'\n",
            " 'pop3']\n",
            "-> proto: unique count = 133 example values = ['tcp' 'udp' 'arp' 'ospf' 'icmp' 'igmp' 'rtp' 'ddp' 'ipv6-frag' 'cftp']\n",
            "-> state: unique count = 9 example values = ['FIN' 'INT' 'CON' 'ECO' 'REQ' 'RST' 'PAR' 'URN' 'no']\n",
            "is_attack distribution:\n",
            "is_attack\n",
            "1    119341\n",
            "0     56000\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# Multiclass encoding (improved)\n",
        "# ============================\n",
        "\n",
        "if MULTI_TARGET in df.columns:\n",
        "    # CHANGED: work on a filtered copy that only keeps rows with a real attack_cat\n",
        "    df_multi = df[df[MULTI_TARGET].notna()].copy()\n",
        "    print(\"\\nMulticlass rows (non-NaN attack_cat):\", len(df_multi))\n",
        "\n",
        "    # Optional: show original distribution\n",
        "    print(\"\\nOriginal attack_cat distribution (non-NaN only):\")\n",
        "    print(df_multi[MULTI_TARGET].value_counts())\n",
        "\n",
        "    # Label encode attack_cat on the filtered df_multi only\n",
        "    le_attack = LabelEncoder()\n",
        "    df_multi['attack_cat_encoded'] = le_attack.fit_transform(\n",
        "        df_multi[MULTI_TARGET].astype(str)\n",
        "    )\n",
        "\n",
        "    print('\\nMulticlass mapping:')\n",
        "    mapping = dict(zip(le_attack.classes_, le_attack.transform(le_attack.classes_)))\n",
        "    print(mapping)\n",
        "else:\n",
        "    df_multi = None\n",
        "    print('No multiclass attack column found; will skip softmax training unless you update MULTI_TARGET.')\n",
        "\n",
        "# For sanity, still show attack_cat distribution on the full df (will include NaNs)\n",
        "if MULTI_TARGET in df.columns:\n",
        "    print('\\nattack_cat value_counts (full df, including NaN):')\n",
        "    print(df[MULTI_TARGET].value_counts(dropna=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "edazb8fsz9s0",
        "outputId": "1c0ebc67-3318-45c4-b50b-34b84cea74b5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Multiclass rows (non-NaN attack_cat): 175341\n",
            "\n",
            "Original attack_cat distribution (non-NaN only):\n",
            "attack_cat\n",
            "Normal            56000\n",
            "Generic           40000\n",
            "Exploits          33393\n",
            "Fuzzers           18184\n",
            "DoS               12264\n",
            "Reconnaissance    10491\n",
            "Analysis           2000\n",
            "Backdoor           1746\n",
            "Shellcode          1133\n",
            "Worms               130\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Multiclass mapping:\n",
            "{'Analysis': np.int64(0), 'Backdoor': np.int64(1), 'DoS': np.int64(2), 'Exploits': np.int64(3), 'Fuzzers': np.int64(4), 'Generic': np.int64(5), 'Normal': np.int64(6), 'Reconnaissance': np.int64(7), 'Shellcode': np.int64(8), 'Worms': np.int64(9)}\n",
            "\n",
            "attack_cat value_counts (full df, including NaN):\n",
            "attack_cat\n",
            "Normal            56000\n",
            "Generic           40000\n",
            "Exploits          33393\n",
            "Fuzzers           18184\n",
            "DoS               12264\n",
            "Reconnaissance    10491\n",
            "Analysis           2000\n",
            "Backdoor           1746\n",
            "Shellcode          1133\n",
            "Worms               130\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# By default drop IPs and timestamp-like fields to avoid leakage and high-cardinality\n",
        "drop_cols = []\n",
        "for cand in ['srcip', 'dstip', 'Stime', 'Ltime', 'stime', 'ltime', 'stime_ms']:\n",
        "    if cand in df.columns:\n",
        "        drop_cols.append(cand)\n",
        "\n",
        "print('Initial drop_cols:', drop_cols)\n",
        "\n",
        "# Numeric columns detection (from df)\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "# exclude target columns\n",
        "exclude = ['is_attack', BINARY_TARGET, 'attack_cat_encoded']\n",
        "numeric_cols = [c for c in numeric_cols if c not in exclude]\n",
        "print('\\nNumeric candidate columns (sample):', numeric_cols[:20])\n",
        "\n",
        "# Categorical columns to encode\n",
        "cat_cols = [c for c in ['service', 'proto', 'state'] if c in df.columns]\n",
        "print('\\nCategorical columns to encode:', cat_cols)\n",
        "\n",
        "# Final features list — for pipeline we'll handle encoding/scaling\n",
        "features = [c for c in numeric_cols + cat_cols if c not in drop_cols]\n",
        "print('\\nFinal features to be used (sample):', features[:40])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yYGx15Ldz9vU",
        "outputId": "6c3f7414-08e2-487e-8870-4e3c2515bbec"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial drop_cols: []\n",
            "\n",
            "Numeric candidate columns (sample): ['ï»¿id', 'dur', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'rate', 'sttl', 'dttl', 'sload', 'dload', 'sloss', 'dloss', 'sinpkt', 'dinpkt', 'sjit', 'djit', 'swin', 'stcpb', 'dtcpb']\n",
            "\n",
            "Categorical columns to encode: ['service', 'proto', 'state']\n",
            "\n",
            "Final features to be used (sample): ['ï»¿id', 'dur', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'rate', 'sttl', 'dttl', 'sload', 'dload', 'sloss', 'dloss', 'sinpkt', 'dinpkt', 'sjit', 'djit', 'swin', 'stcpb', 'dtcpb', 'dwin', 'tcprtt', 'synack', 'ackdat', 'smean', 'dmean', 'trans_depth', 'response_body_len', 'ct_srv_src', 'ct_state_ttl', 'ct_dst_ltm', 'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'is_ftp_login', 'ct_ftp_cmd', 'ct_flw_http_mthd', 'ct_src_ltm', 'ct_srv_dst', 'is_sm_ips_ports']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
        "\n",
        "# Define preprocessing steps\n",
        "num_features = [c for c in features if c in df.columns and np.issubdtype(df[c].dtype, np.number)]\n",
        "cat_features = [c for c in features if c in df.columns and c not in num_features]\n",
        "\n",
        "num_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "cat_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='unknown')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', num_transformer, num_features),\n",
        "    ('cat', cat_transformer, cat_features)\n",
        "], remainder='drop')\n",
        "\n",
        "print('num_features count:', len(num_features))\n",
        "print('cat_features count:', len(cat_features))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5k5czVpFz9x8",
        "outputId": "121cfee2-c241-4f3e-f6d0-8518e987dff5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_features count: 40\n",
            "cat_features count: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# Binary classification\n",
        "# ============================\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "print('\\n================ BINARY CLASSIFICATION ================\\n')\n",
        "\n",
        "# Prepare data for binary classification\n",
        "X = df[features]\n",
        "y = df['is_attack']\n",
        "\n",
        "# Stratified split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, stratify=y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Neural network pipeline (same preprocessing)\n",
        "mlp_model = Pipeline(steps=[\n",
        "    ('preproc', preprocessor),\n",
        "    ('clf', MLPClassifier(\n",
        "        hidden_layer_sizes=(64, 32),\n",
        "        activation='relu',\n",
        "        solver='adam',\n",
        "        max_iter=200,\n",
        "        random_state=42,\n",
        "        early_stopping=True,\n",
        "        verbose=True\n",
        "    ))\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "k9RjLM6jz90s",
        "outputId": "489058d8-c2e0-46ce-ceea-55136e68214d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ BINARY CLASSIFICATION ================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Training MLPClassifier (binary)...')\n",
        "mlp_model.fit(X_train, y_train)\n",
        "print('Done.')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BlU9Pbj0nfe",
        "outputId": "d11ec653-4ff4-4130-fc7c-5a4f78edb589"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training MLPClassifier (binary)...\n",
            "Iteration 1, loss = 0.14329366\n",
            "Validation score: 0.948318\n",
            "Iteration 2, loss = 0.10062198\n",
            "Validation score: 0.955660\n",
            "Iteration 3, loss = 0.09325353\n",
            "Validation score: 0.956658\n",
            "Iteration 4, loss = 0.08567800\n",
            "Validation score: 0.964357\n",
            "Iteration 5, loss = 0.07821420\n",
            "Validation score: 0.967707\n",
            "Iteration 6, loss = 0.07155414\n",
            "Validation score: 0.967137\n",
            "Iteration 7, loss = 0.06597820\n",
            "Validation score: 0.969276\n",
            "Iteration 8, loss = 0.06168312\n",
            "Validation score: 0.972840\n",
            "Iteration 9, loss = 0.05893828\n",
            "Validation score: 0.972555\n",
            "Iteration 10, loss = 0.05705680\n",
            "Validation score: 0.972840\n",
            "Iteration 11, loss = 0.05520030\n",
            "Validation score: 0.972198\n",
            "Iteration 12, loss = 0.05371209\n",
            "Validation score: 0.976618\n",
            "Iteration 13, loss = 0.05292465\n",
            "Validation score: 0.973339\n",
            "Iteration 14, loss = 0.05143733\n",
            "Validation score: 0.972626\n",
            "Iteration 15, loss = 0.05097852\n",
            "Validation score: 0.975335\n",
            "Iteration 16, loss = 0.04912985\n",
            "Validation score: 0.974907\n",
            "Iteration 17, loss = 0.04894657\n",
            "Validation score: 0.976832\n",
            "Iteration 18, loss = 0.04819981\n",
            "Validation score: 0.973624\n",
            "Iteration 19, loss = 0.04773588\n",
            "Validation score: 0.976975\n",
            "Iteration 20, loss = 0.04694632\n",
            "Validation score: 0.978400\n",
            "Iteration 21, loss = 0.04540905\n",
            "Validation score: 0.978044\n",
            "Iteration 22, loss = 0.04584814\n",
            "Validation score: 0.977117\n",
            "Iteration 23, loss = 0.04587413\n",
            "Validation score: 0.979113\n",
            "Iteration 24, loss = 0.04390440\n",
            "Validation score: 0.979327\n",
            "Iteration 25, loss = 0.04435757\n",
            "Validation score: 0.978044\n",
            "Iteration 26, loss = 0.04336450\n",
            "Validation score: 0.976476\n",
            "Iteration 27, loss = 0.04284063\n",
            "Validation score: 0.979755\n",
            "Iteration 28, loss = 0.04324503\n",
            "Validation score: 0.978899\n",
            "Iteration 29, loss = 0.04232959\n",
            "Validation score: 0.977973\n",
            "Iteration 30, loss = 0.04156241\n",
            "Validation score: 0.979683\n",
            "Iteration 31, loss = 0.04209071\n",
            "Validation score: 0.980681\n",
            "Iteration 32, loss = 0.04079992\n",
            "Validation score: 0.980254\n",
            "Iteration 33, loss = 0.04074454\n",
            "Validation score: 0.978828\n",
            "Iteration 34, loss = 0.03965518\n",
            "Validation score: 0.980325\n",
            "Iteration 35, loss = 0.03935293\n",
            "Validation score: 0.978685\n",
            "Iteration 36, loss = 0.04012588\n",
            "Validation score: 0.981893\n",
            "Iteration 37, loss = 0.03951001\n",
            "Validation score: 0.981252\n",
            "Iteration 38, loss = 0.03892737\n",
            "Validation score: 0.982606\n",
            "Iteration 39, loss = 0.03815891\n",
            "Validation score: 0.979826\n",
            "Iteration 40, loss = 0.03833675\n",
            "Validation score: 0.980254\n",
            "Iteration 41, loss = 0.03768050\n",
            "Validation score: 0.981466\n",
            "Iteration 42, loss = 0.03739484\n",
            "Validation score: 0.982107\n",
            "Iteration 43, loss = 0.03750888\n",
            "Validation score: 0.982678\n",
            "Iteration 44, loss = 0.03748895\n",
            "Validation score: 0.982392\n",
            "Iteration 45, loss = 0.03635381\n",
            "Validation score: 0.980468\n",
            "Iteration 46, loss = 0.03663323\n",
            "Validation score: 0.981180\n",
            "Iteration 47, loss = 0.03647798\n",
            "Validation score: 0.980396\n",
            "Iteration 48, loss = 0.03569725\n",
            "Validation score: 0.981466\n",
            "Iteration 49, loss = 0.03616674\n",
            "Validation score: 0.982321\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_nn = mlp_model.predict(X_test)\n",
        "print('\\nClassification report (MLP binary):')\n",
        "print(classification_report(y_test, y_pred_nn, digits=4))\n",
        "print('\\nConfusion matrix:')\n",
        "print(confusion_matrix(y_test, y_pred_nn))\n",
        "\n",
        "# Saving the binary model\n",
        "joblib.dump(mlp_model, 'mlp_attack_model.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wANiuVC50niY",
        "outputId": "e9f9ed5c-1948-4afb-a45e-df401744d3e1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification report (MLP binary):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9785    0.9685    0.9735     11200\n",
            "           1     0.9853    0.9900    0.9876     23869\n",
            "\n",
            "    accuracy                         0.9831     35069\n",
            "   macro avg     0.9819    0.9793    0.9806     35069\n",
            "weighted avg     0.9831    0.9831    0.9831     35069\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[10847   353]\n",
            " [  238 23631]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mlp_attack_model.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# Multiclass classification (attack types)\n",
        "# ============================\n",
        "# import tensorflow as tf\n",
        "# from tensorflow.keras import layers, models, regularizers\n",
        "# from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# print('\\n================ MULTICLASS CLASSIFICATION ================\\n')\n",
        "\n",
        "# ============================\n",
        "# NEW ADVANCED MULTICLASS SECTION\n",
        "# ============================\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "print('\\n================ MULTICLASS CLASSIFICATION (MODERN MLP) ================\\n')\n",
        "\n",
        "if df_multi is None:\n",
        "    raise ValueError(\"df_multi is None; MULTI_TARGET column not found.\")\n",
        "\n",
        "# 1. Setup Data\n",
        "X_multi = df_multi[features]\n",
        "y_multi = df_multi['attack_cat_encoded']\n",
        "\n",
        "# Stratified Split\n",
        "X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(\n",
        "    X_multi, y_multi, stratify=y_multi, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 2. Advanced Preprocessing: Separate Categorical vs Numerical\n",
        "# We need this separation because we are going to use \"Embeddings\" for text,\n",
        "# which works much better than OneHotEncoding for things like 'service' or 'proto'.\n",
        "\n",
        "cat_cols_to_embed = ['service', 'proto', 'state']\n",
        "# Filter to ensure these cols actually exist in features\n",
        "cat_cols_to_embed = [c for c in cat_cols_to_embed if c in X_train_m.columns]\n",
        "num_cols = [c for c in features if c not in cat_cols_to_embed]\n",
        "\n",
        "print(f\"Embedding Categoricals: {cat_cols_to_embed}\")\n",
        "print(f\"Scaling Numericals: {len(num_cols)} columns\")\n",
        "\n",
        "# A. Scale Numericals\n",
        "scaler = StandardScaler()\n",
        "X_train_num = scaler.fit_transform(X_train_m[num_cols])\n",
        "X_test_num = scaler.transform(X_test_m[num_cols])\n",
        "\n",
        "# B. Encode Categoricals (Ordinal)\n",
        "# We map strings to integers (0, 1, 2...) so the Neural Net can learn their meaning\n",
        "ord_enc = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
        "X_train_cat = ord_enc.fit_transform(X_train_m[cat_cols_to_embed])\n",
        "X_test_cat = ord_enc.transform(X_test_m[cat_cols_to_embed])\n",
        "\n",
        "# Handle unknown categories (replace -1 with a new index)\n",
        "for i in range(X_train_cat.shape[1]):\n",
        "    max_val = X_train_cat[:, i].max()\n",
        "    # Replace unknowns (-1) with max_val + 1 so it has its own ID\n",
        "    fill_val = max_val + 1\n",
        "    X_train_cat[X_train_cat[:, i] == -1, i] = fill_val\n",
        "    X_test_cat[X_test_cat[:, i] == -1, i] = fill_val\n",
        "\n",
        "# 3. Compute Class Weights (To fix imbalance)\n",
        "classes = np.unique(y_train_m)\n",
        "weights = compute_class_weight('balanced', classes=classes, y=y_train_m)\n",
        "class_weights_dict = {int(cls): float(w) for cls, w in zip(classes, weights)}\n",
        "print(\"Class weights enabled:\", class_weights_dict)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "141sRS4B0nlW",
        "outputId": "5098c98b-c40c-41e8-d066-3ea38537ad7f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ MULTICLASS CLASSIFICATION (MODERN MLP) ================\n",
            "\n",
            "Embedding Categoricals: ['service', 'proto', 'state']\n",
            "Scaling Numericals: 40 columns\n",
            "Class weights enabled: {0: 8.767, 1: 10.040944881889764, 2: 1.4297421261848946, 3: 0.5250879688552819, 4: 0.9642675465731766, 5: 0.43835, 6: 0.31310714285714286, 7: 1.6712975098296199, 8: 15.482560706401767, 9: 134.87692307692308}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# REPLACE YOUR MODEL DEFINITION WITH THIS MOBILE-CNN\n",
        "# ==========================================\n",
        "\n",
        "# def build_mobile_cnn(num_input_shape, cat_input_shapes, cat_counts, num_classes):\n",
        "#     # --- 1. Inputs ---\n",
        "#     input_num = layers.Input(shape=num_input_shape, name=\"input_num\")\n",
        "\n",
        "#     inputs_cat = []\n",
        "#     embeddings = []\n",
        "\n",
        "#     # Use smaller embeddings for mobile (output_dim=8 is usually enough)\n",
        "#     for i, (col_name, count) in enumerate(zip(cat_cols_to_embed, cat_counts)):\n",
        "#         inp = layers.Input(shape=(1,), name=f\"input_{col_name}\")\n",
        "#         inputs_cat.append(inp)\n",
        "\n",
        "#         # Squeeze embedding size for memory efficiency\n",
        "#         emb_dim = min(16, int(count/2) + 1)\n",
        "#         emb = layers.Embedding(input_dim=int(count)+2, output_dim=emb_dim)(inp)\n",
        "#         emb = layers.Flatten()(emb)\n",
        "#         embeddings.append(emb)\n",
        "\n",
        "#     # --- 2. Feature Fusion ---\n",
        "#     # Combine everything into one flat vector\n",
        "#     x = layers.Concatenate()(embeddings + [input_num])\n",
        "\n",
        "#     # --- 3. Reshape for CNN ---\n",
        "#     # The CNN needs a 3D input: (Batch, Steps, Channels)\n",
        "#     # We treat the concatenated features as a \"time series\" of length 1, with N channels\n",
        "#     # Or more effectively for 1D CNN: Reshape to (Features, 1)\n",
        "#     x = layers.Reshape((-1, 1))(x)\n",
        "\n",
        "#     # --- 4. Mobile-Optimized CNN Block ---\n",
        "\n",
        "#     # Conv Block 1\n",
        "#     x = layers.Conv1D(filters=64, kernel_size=3, padding='same')(x)\n",
        "#     x = layers.BatchNormalization()(x)\n",
        "#     x = layers.Activation('swish')(x)\n",
        "#     x = layers.MaxPooling1D(pool_size=2)(x)\n",
        "\n",
        "#     # Conv Block 2\n",
        "#     x = layers.Conv1D(filters=128, kernel_size=3, padding='same')(x)\n",
        "#     x = layers.BatchNormalization()(x)\n",
        "#     x = layers.Activation('swish')(x)\n",
        "#     # Global Average Pooling is the key for mobile:\n",
        "#     # It replaces the massive \"Flatten + Dense\" layers that eat up memory.\n",
        "#     x = layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "#     # --- 5. Output Head ---\n",
        "#     x = layers.Dropout(0.2)(x)\n",
        "#     outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "#     model = models.Model(inputs=inputs_cat + [input_num], outputs=outputs)\n",
        "#     return model\n",
        "\n",
        "# # Setup inputs\n",
        "# cat_counts = [int(X_train_cat[:, i].max()) + 1 for i in range(len(cat_cols_to_embed))]\n",
        "# num_classes = len(np.unique(y_train_m))\n",
        "# ==========================================\n",
        "# REPLACE WITH THIS HYBRID MLP\n",
        "# ==========================================\n",
        "\n",
        "# def build_hybrid_mlp(num_input_shape, cat_input_shapes, cat_counts, num_classes): # version 2\n",
        "#     # --- 1. Inputs ---\n",
        "#     input_num = layers.Input(shape=num_input_shape, name=\"input_num\")\n",
        "\n",
        "#     inputs_cat = []\n",
        "#     embeddings = []\n",
        "\n",
        "#     # Keep embeddings small for mobile efficiency\n",
        "#     for i, (col_name, count) in enumerate(zip(cat_cols_to_embed, cat_counts)):\n",
        "#         inp = layers.Input(shape=(1,), name=f\"input_{col_name}\")\n",
        "#         inputs_cat.append(inp)\n",
        "\n",
        "#         emb_dim = min(10, int(count/2) + 1) # Small efficient embeddings\n",
        "#         emb = layers.Embedding(input_dim=int(count)+2, output_dim=emb_dim)(inp)\n",
        "#         emb = layers.Flatten()(emb)\n",
        "#         embeddings.append(emb)\n",
        "\n",
        "#     # --- 2. Feature Fusion ---\n",
        "#     # Concatenate everything (Numerics + Embeddings)\n",
        "#     x = layers.Concatenate()(embeddings + [input_num])\n",
        "\n",
        "#     # --- 3. Optimized Dense Block (The \"Brain\") ---\n",
        "#     # We use \"Swish\" activation and BatchNormalization to speed up learning\n",
        "\n",
        "#     # Layer 1 (512 neurons)\n",
        "#     x = layers.Dense(512)(x)\n",
        "#     x = layers.BatchNormalization()(x)\n",
        "#     x = layers.Activation('swish')(x)\n",
        "#     x = layers.Dropout(0.4)(x) # Higher dropout because model is bigger\n",
        "\n",
        "#     # Layer 2 (256 neurons)\n",
        "#     x = layers.Dense(256)(x)\n",
        "#     x = layers.BatchNormalization()(x)\n",
        "#     x = layers.Activation('swish')(x)\n",
        "#     x = layers.Dropout(0.3)(x)\n",
        "\n",
        "#     # Layer 3 (128 neurons)\n",
        "#     x = layers.Dense(128)(x)\n",
        "#     x = layers.BatchNormalization()(x)\n",
        "#     x = layers.Activation('swish')(x)\n",
        "#     x = layers.Dropout(0.2)(x)\n",
        "\n",
        "#     # --- 4. Output ---\n",
        "#     outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "#     model = models.Model(inputs=inputs_cat + [input_num], outputs=outputs)\n",
        "#     return model\n",
        "\n",
        "# version 3\n",
        "def build_residual_mlp(num_input_shape, cat_input_shapes, cat_counts, num_classes):\n",
        "    # --- 1. Inputs ---\n",
        "    input_num = layers.Input(shape=num_input_shape, name=\"input_num\")\n",
        "    inputs_cat = []\n",
        "    embeddings = []\n",
        "\n",
        "    # Slightly larger embeddings for better representation\n",
        "    for i, (col_name, count) in enumerate(zip(cat_cols_to_embed, cat_counts)):\n",
        "        inp = layers.Input(shape=(1,), name=f\"input_{col_name}\")\n",
        "        inputs_cat.append(inp)\n",
        "\n",
        "        # Increase dim slightly: min(50, count/2)\n",
        "        emb_dim = min(16, int(count/2) + 1)\n",
        "        emb = layers.Embedding(input_dim=int(count)+2, output_dim=emb_dim)(inp)\n",
        "        emb = layers.Flatten()(emb)\n",
        "        embeddings.append(emb)\n",
        "\n",
        "    # --- 2. Feature Fusion ---\n",
        "    x = layers.Concatenate()(embeddings + [input_num])\n",
        "\n",
        "    # Project to a fixed size before residual blocks\n",
        "    x = layers.Dense(256, activation=\"relu\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    # --- 3. Residual Blocks (The \"ResNet\" logic) ---\n",
        "    # Block 1\n",
        "    residual = x\n",
        "    x = layers.Dense(256, activation=\"swish\", kernel_regularizer=regularizers.l2(0.0001))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.Dense(256, activation=\"swish\", kernel_regularizer=regularizers.l2(0.0001))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Add()([x, residual]) # Skip Connection\n",
        "\n",
        "    # Block 2\n",
        "    residual = x\n",
        "    x = layers.Dense(256, activation=\"swish\", kernel_regularizer=regularizers.l2(0.0001))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.Dense(256, activation=\"swish\", kernel_regularizer=regularizers.l2(0.0001))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Add()([x, residual]) # Skip Connection\n",
        "\n",
        "    # --- 4. Output ---\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs=inputs_cat + [input_num], outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# make new model and copy the weights: \"save weight\" and \"load weight\"??\n",
        "# model 1 (what we already have) (2 layer weight1, weight2) , duplicate Model 2: Hidden layer 1 and idden layer 2 => non trainable (from model 1 since model 1 has 2 hidden layers)\n",
        "# add this layer and use the 2 layer in transfer learning\n",
        "\n",
        "# Setup inputs\n",
        "cat_counts = [int(X_train_cat[:, i].max()) + 1 for i in range(len(cat_cols_to_embed))]\n",
        "num_classes = len(np.unique(y_train_m))"
      ],
      "metadata": {
        "id": "kU4LEnct0noJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Build the Mobile CNN\n",
        "# model = build_mobile_cnn(\n",
        "#     num_input_shape=(X_train_num.shape[1],),\n",
        "#     cat_input_shapes=[(1,) for _ in cat_cols_to_embed],\n",
        "#     cat_counts=cat_counts,\n",
        "#     num_classes=num_classes\n",
        "# )\n",
        "\n",
        "# # Compile (Note: Lower learning rate for CNNs usually helps stability)\n",
        "# model.compile(\n",
        "#     optimizer=tf.keras.optimizers.AdamW(learning_rate=0.001, weight_decay=1e-4),\n",
        "#     loss='sparse_categorical_crossentropy',\n",
        "#     metrics=['accuracy']\n",
        "# )\n",
        "\n",
        "# model.summary()\n",
        "\n",
        "# Build version 2\n",
        "# model = build_hybrid_mlp(\n",
        "#     num_input_shape=(X_train_num.shape[1],),\n",
        "#     cat_input_shapes=[(1,) for _ in cat_cols_to_embed],\n",
        "#     cat_counts=cat_counts,\n",
        "#     num_classes=num_classes\n",
        "# )\n",
        "\n",
        "# # Compile\n",
        "# model.compile(\n",
        "#     optimizer=tf.keras.optimizers.AdamW(learning_rate=0.001, weight_decay=1e-4),\n",
        "#     loss='sparse_categorical_crossentropy',\n",
        "#     metrics=['accuracy']\n",
        "# )\n",
        "\n",
        "# version 3\n",
        "# Build the improved model\n",
        "model = build_residual_mlp(\n",
        "    num_input_shape=(X_train_num.shape[1],),\n",
        "    cat_input_shapes=[(1,) for _ in cat_cols_to_embed],\n",
        "    cat_counts=cat_counts,\n",
        "    num_classes=num_classes\n",
        ")\n",
        "\n",
        "# Compile using a small Label Smoothing to prevent overconfidence\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.AdamW(learning_rate=0.001, weight_decay=1e-4),\n",
        "    # loss=tf.keras.losses.SparseCategoricalCrossentropy(label_smoothing=0.1),\n",
        "    loss='sparse_categorical_crossentropy',  # Removed label_smoothing\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3V9--6aYz921",
        "outputId": "c2faa232-2867-43c6-f717-1c9f64049cb8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_service       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_proto         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_state         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m7\u001b[0m)      │        \u001b[38;5;34m105\u001b[0m │ input_service[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │      \u001b[38;5;34m2,160\u001b[0m │ input_proto[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m5\u001b[0m)      │         \u001b[38;5;34m55\u001b[0m │ input_state[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_num           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m68\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                     │                   │            │ flatten_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                     │                   │            │ input_num[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m17,664\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m65,792\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m65,792\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │                   │            │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m65,792\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m65,792\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │                   │            │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │      \u001b[38;5;34m2,570\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_service       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_proto         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_state         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">105</span> │ input_service[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,160</span> │ input_proto[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span> │ input_state[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_num           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                     │                   │            │ flatten_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                     │                   │            │ input_num[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">17,664</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │                   │            │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │                   │            │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m290,842\u001b[0m (1.11 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">290,842</span> (1.11 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m288,282\u001b[0m (1.10 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">288,282</span> (1.10 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,560\u001b[0m (10.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,560</span> (10.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LYAQLxgKhCwT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 5. Train the Model\n",
        "# We must prepare inputs as a list: [Cat1, Cat2, Cat3, ..., Numericals]\n",
        "train_inputs = [X_train_cat[:, i] for i in range(X_train_cat.shape[1])] + [X_train_num]\n",
        "test_inputs = [X_test_cat[:, i] for i in range(X_test_cat.shape[1])] + [X_test_num]\n",
        "\n",
        "# history = model.fit(\n",
        "#     train_inputs,\n",
        "#     y_train_m,\n",
        "#     epochs=100,\n",
        "#     batch_size=1024,\n",
        "#     # class_weight=class_weights_dict, # CRITICAL: Handles the imbalance\n",
        "#     validation_split=0.2,\n",
        "#     callbacks=[\n",
        "#         tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights=True),\n",
        "#         tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6, verbose=1)\n",
        "#     ],\n",
        "#     verbose=1\n",
        "# )\n",
        "\n",
        "history = model.fit(\n",
        "    train_inputs,\n",
        "    y_train_m,\n",
        "    epochs=100,\n",
        "    batch_size=512,  # 512 is stable for MLPs\n",
        "    # class_weight=class_weights_dict,  # <-- KEEP COMMENTED OUT for max accuracy\n",
        "    validation_split=0.2,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights=True),\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6, verbose=1)\n",
        "    ],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-1120Pt2lKc",
        "outputId": "8ee6c38c-41cd-4030-b285-cf8af47c4ace"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 55ms/step - accuracy: 0.6843 - loss: 1.1716 - val_accuracy: 0.7879 - val_loss: 0.7194 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.7731 - loss: 0.7127 - val_accuracy: 0.8003 - val_loss: 0.6403 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.7844 - loss: 0.6690 - val_accuracy: 0.8029 - val_loss: 0.6225 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 71ms/step - accuracy: 0.7920 - loss: 0.6406 - val_accuracy: 0.8005 - val_loss: 0.6080 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 49ms/step - accuracy: 0.7978 - loss: 0.6152 - val_accuracy: 0.8061 - val_loss: 0.5831 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - accuracy: 0.8048 - loss: 0.5925 - val_accuracy: 0.8102 - val_loss: 0.5582 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 52ms/step - accuracy: 0.8071 - loss: 0.5748 - val_accuracy: 0.8135 - val_loss: 0.5425 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 52ms/step - accuracy: 0.8189 - loss: 0.5432 - val_accuracy: 0.8226 - val_loss: 0.5201 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 52ms/step - accuracy: 0.8187 - loss: 0.5279 - val_accuracy: 0.8310 - val_loss: 0.5027 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.8229 - loss: 0.5134 - val_accuracy: 0.8259 - val_loss: 0.4882 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 52ms/step - accuracy: 0.8250 - loss: 0.4997 - val_accuracy: 0.8302 - val_loss: 0.4776 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.8259 - loss: 0.4916 - val_accuracy: 0.8317 - val_loss: 0.4760 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.8304 - loss: 0.4774 - val_accuracy: 0.8361 - val_loss: 0.4576 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 74ms/step - accuracy: 0.8302 - loss: 0.4757 - val_accuracy: 0.8346 - val_loss: 0.4589 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 48ms/step - accuracy: 0.8279 - loss: 0.4708 - val_accuracy: 0.8361 - val_loss: 0.4498 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.8316 - loss: 0.4623 - val_accuracy: 0.8312 - val_loss: 0.4488 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 56ms/step - accuracy: 0.8346 - loss: 0.4518 - val_accuracy: 0.8347 - val_loss: 0.4423 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.8335 - loss: 0.4500 - val_accuracy: 0.8356 - val_loss: 0.4435 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 0.8350 - loss: 0.4464 - val_accuracy: 0.8375 - val_loss: 0.4332 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.8355 - loss: 0.4450 - val_accuracy: 0.8370 - val_loss: 0.4314 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - accuracy: 0.8370 - loss: 0.4402 - val_accuracy: 0.8372 - val_loss: 0.4335 - learning_rate: 0.0010\n",
            "Epoch 22/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 49ms/step - accuracy: 0.8358 - loss: 0.4367 - val_accuracy: 0.8396 - val_loss: 0.4239 - learning_rate: 0.0010\n",
            "Epoch 23/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.8375 - loss: 0.4344 - val_accuracy: 0.8339 - val_loss: 0.4289 - learning_rate: 0.0010\n",
            "Epoch 24/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 52ms/step - accuracy: 0.8374 - loss: 0.4370 - val_accuracy: 0.8405 - val_loss: 0.4191 - learning_rate: 0.0010\n",
            "Epoch 25/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 52ms/step - accuracy: 0.8367 - loss: 0.4355 - val_accuracy: 0.8439 - val_loss: 0.4173 - learning_rate: 0.0010\n",
            "Epoch 26/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 0.8401 - loss: 0.4292 - val_accuracy: 0.8427 - val_loss: 0.4163 - learning_rate: 0.0010\n",
            "Epoch 27/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.8401 - loss: 0.4284 - val_accuracy: 0.8426 - val_loss: 0.4170 - learning_rate: 0.0010\n",
            "Epoch 28/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.8396 - loss: 0.4280 - val_accuracy: 0.8422 - val_loss: 0.4188 - learning_rate: 0.0010\n",
            "Epoch 29/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.8420 - loss: 0.4201 - val_accuracy: 0.8468 - val_loss: 0.4135 - learning_rate: 0.0010\n",
            "Epoch 30/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.8408 - loss: 0.4262 - val_accuracy: 0.8401 - val_loss: 0.4141 - learning_rate: 0.0010\n",
            "Epoch 31/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 52ms/step - accuracy: 0.8385 - loss: 0.4257 - val_accuracy: 0.8439 - val_loss: 0.4151 - learning_rate: 0.0010\n",
            "Epoch 32/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 53ms/step - accuracy: 0.8420 - loss: 0.4210 - val_accuracy: 0.8441 - val_loss: 0.4154 - learning_rate: 0.0010\n",
            "Epoch 33/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 54ms/step - accuracy: 0.8405 - loss: 0.4238 - val_accuracy: 0.8417 - val_loss: 0.4203 - learning_rate: 0.0010\n",
            "Epoch 34/100\n",
            "\u001b[1m219/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8429 - loss: 0.4204\n",
            "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 48ms/step - accuracy: 0.8429 - loss: 0.4204 - val_accuracy: 0.8446 - val_loss: 0.4135 - learning_rate: 0.0010\n",
            "Epoch 35/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 54ms/step - accuracy: 0.8463 - loss: 0.4057 - val_accuracy: 0.8491 - val_loss: 0.3971 - learning_rate: 2.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 53ms/step - accuracy: 0.8500 - loss: 0.3962 - val_accuracy: 0.8485 - val_loss: 0.3986 - learning_rate: 2.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 54ms/step - accuracy: 0.8495 - loss: 0.3978 - val_accuracy: 0.8492 - val_loss: 0.3944 - learning_rate: 2.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.8493 - loss: 0.3951 - val_accuracy: 0.8490 - val_loss: 0.3929 - learning_rate: 2.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.8506 - loss: 0.3928 - val_accuracy: 0.8525 - val_loss: 0.3901 - learning_rate: 2.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.8514 - loss: 0.3903 - val_accuracy: 0.8514 - val_loss: 0.3897 - learning_rate: 2.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.8520 - loss: 0.3873 - val_accuracy: 0.8529 - val_loss: 0.3886 - learning_rate: 2.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.8517 - loss: 0.3907 - val_accuracy: 0.8514 - val_loss: 0.3894 - learning_rate: 2.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 52ms/step - accuracy: 0.8515 - loss: 0.3879 - val_accuracy: 0.8527 - val_loss: 0.3876 - learning_rate: 2.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.8533 - loss: 0.3861 - val_accuracy: 0.8529 - val_loss: 0.3861 - learning_rate: 2.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 52ms/step - accuracy: 0.8508 - loss: 0.3895 - val_accuracy: 0.8519 - val_loss: 0.3878 - learning_rate: 2.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 52ms/step - accuracy: 0.8523 - loss: 0.3861 - val_accuracy: 0.8535 - val_loss: 0.3849 - learning_rate: 2.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.8559 - loss: 0.3800 - val_accuracy: 0.8539 - val_loss: 0.3847 - learning_rate: 2.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.8502 - loss: 0.3877 - val_accuracy: 0.8520 - val_loss: 0.3859 - learning_rate: 2.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 49ms/step - accuracy: 0.8536 - loss: 0.3824 - val_accuracy: 0.8536 - val_loss: 0.3854 - learning_rate: 2.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.8550 - loss: 0.3789 - val_accuracy: 0.8532 - val_loss: 0.3841 - learning_rate: 2.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.8540 - loss: 0.3827 - val_accuracy: 0.8540 - val_loss: 0.3827 - learning_rate: 2.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.8546 - loss: 0.3798 - val_accuracy: 0.8539 - val_loss: 0.3833 - learning_rate: 2.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - accuracy: 0.8526 - loss: 0.3817 - val_accuracy: 0.8543 - val_loss: 0.3856 - learning_rate: 2.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.8545 - loss: 0.3801 - val_accuracy: 0.8556 - val_loss: 0.3822 - learning_rate: 2.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 0.8562 - loss: 0.3787 - val_accuracy: 0.8536 - val_loss: 0.3834 - learning_rate: 2.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.8541 - loss: 0.3793 - val_accuracy: 0.8549 - val_loss: 0.3812 - learning_rate: 2.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.8561 - loss: 0.3761 - val_accuracy: 0.8519 - val_loss: 0.3844 - learning_rate: 2.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 53ms/step - accuracy: 0.8574 - loss: 0.3696 - val_accuracy: 0.8544 - val_loss: 0.3817 - learning_rate: 2.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 53ms/step - accuracy: 0.8576 - loss: 0.3707 - val_accuracy: 0.8554 - val_loss: 0.3806 - learning_rate: 2.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 54ms/step - accuracy: 0.8562 - loss: 0.3758 - val_accuracy: 0.8550 - val_loss: 0.3801 - learning_rate: 2.0000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.8557 - loss: 0.3768 - val_accuracy: 0.8526 - val_loss: 0.3827 - learning_rate: 2.0000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.8544 - loss: 0.3746 - val_accuracy: 0.8551 - val_loss: 0.3797 - learning_rate: 2.0000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.8565 - loss: 0.3756 - val_accuracy: 0.8552 - val_loss: 0.3810 - learning_rate: 2.0000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.8546 - loss: 0.3743 - val_accuracy: 0.8534 - val_loss: 0.3823 - learning_rate: 2.0000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.8545 - loss: 0.3771 - val_accuracy: 0.8540 - val_loss: 0.3828 - learning_rate: 2.0000e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 54ms/step - accuracy: 0.8555 - loss: 0.3742 - val_accuracy: 0.8559 - val_loss: 0.3787 - learning_rate: 2.0000e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 54ms/step - accuracy: 0.8553 - loss: 0.3744 - val_accuracy: 0.8565 - val_loss: 0.3794 - learning_rate: 2.0000e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.8586 - loss: 0.3703 - val_accuracy: 0.8557 - val_loss: 0.3799 - learning_rate: 2.0000e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.8557 - loss: 0.3717 - val_accuracy: 0.8544 - val_loss: 0.3801 - learning_rate: 2.0000e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 53ms/step - accuracy: 0.8572 - loss: 0.3717 - val_accuracy: 0.8555 - val_loss: 0.3798 - learning_rate: 2.0000e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8554 - loss: 0.3759\n",
            "Epoch 71: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.8554 - loss: 0.3759 - val_accuracy: 0.8541 - val_loss: 0.3816 - learning_rate: 2.0000e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.8577 - loss: 0.3687 - val_accuracy: 0.8565 - val_loss: 0.3766 - learning_rate: 4.0000e-05\n",
            "Epoch 73/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.8599 - loss: 0.3657 - val_accuracy: 0.8563 - val_loss: 0.3766 - learning_rate: 4.0000e-05\n",
            "Epoch 74/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 49ms/step - accuracy: 0.8613 - loss: 0.3600 - val_accuracy: 0.8567 - val_loss: 0.3764 - learning_rate: 4.0000e-05\n",
            "Epoch 75/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.8582 - loss: 0.3661 - val_accuracy: 0.8570 - val_loss: 0.3759 - learning_rate: 4.0000e-05\n",
            "Epoch 76/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.8597 - loss: 0.3662 - val_accuracy: 0.8569 - val_loss: 0.3762 - learning_rate: 4.0000e-05\n",
            "Epoch 77/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 53ms/step - accuracy: 0.8598 - loss: 0.3646 - val_accuracy: 0.8556 - val_loss: 0.3766 - learning_rate: 4.0000e-05\n",
            "Epoch 78/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 54ms/step - accuracy: 0.8604 - loss: 0.3633 - val_accuracy: 0.8569 - val_loss: 0.3760 - learning_rate: 4.0000e-05\n",
            "Epoch 79/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 54ms/step - accuracy: 0.8609 - loss: 0.3612 - val_accuracy: 0.8569 - val_loss: 0.3756 - learning_rate: 4.0000e-05\n",
            "Epoch 80/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.8612 - loss: 0.3629 - val_accuracy: 0.8568 - val_loss: 0.3756 - learning_rate: 4.0000e-05\n",
            "Epoch 81/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.8619 - loss: 0.3613 - val_accuracy: 0.8571 - val_loss: 0.3758 - learning_rate: 4.0000e-05\n",
            "Epoch 82/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 54ms/step - accuracy: 0.8598 - loss: 0.3595 - val_accuracy: 0.8566 - val_loss: 0.3761 - learning_rate: 4.0000e-05\n",
            "Epoch 83/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.8597 - loss: 0.3625 - val_accuracy: 0.8569 - val_loss: 0.3755 - learning_rate: 4.0000e-05\n",
            "Epoch 84/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 54ms/step - accuracy: 0.8605 - loss: 0.3619 - val_accuracy: 0.8570 - val_loss: 0.3756 - learning_rate: 4.0000e-05\n",
            "Epoch 85/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 54ms/step - accuracy: 0.8576 - loss: 0.3666 - val_accuracy: 0.8571 - val_loss: 0.3757 - learning_rate: 4.0000e-05\n",
            "Epoch 86/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 54ms/step - accuracy: 0.8596 - loss: 0.3622 - val_accuracy: 0.8571 - val_loss: 0.3756 - learning_rate: 4.0000e-05\n",
            "Epoch 87/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.8606 - loss: 0.3604 - val_accuracy: 0.8569 - val_loss: 0.3750 - learning_rate: 4.0000e-05\n",
            "Epoch 88/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 52ms/step - accuracy: 0.8620 - loss: 0.3585 - val_accuracy: 0.8571 - val_loss: 0.3751 - learning_rate: 4.0000e-05\n",
            "Epoch 89/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 49ms/step - accuracy: 0.8616 - loss: 0.3572 - val_accuracy: 0.8567 - val_loss: 0.3748 - learning_rate: 4.0000e-05\n",
            "Epoch 90/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.8613 - loss: 0.3608 - val_accuracy: 0.8572 - val_loss: 0.3752 - learning_rate: 4.0000e-05\n",
            "Epoch 91/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 54ms/step - accuracy: 0.8604 - loss: 0.3605 - val_accuracy: 0.8572 - val_loss: 0.3747 - learning_rate: 4.0000e-05\n",
            "Epoch 92/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 53ms/step - accuracy: 0.8610 - loss: 0.3570 - val_accuracy: 0.8577 - val_loss: 0.3748 - learning_rate: 4.0000e-05\n",
            "Epoch 93/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 53ms/step - accuracy: 0.8599 - loss: 0.3635 - val_accuracy: 0.8576 - val_loss: 0.3748 - learning_rate: 4.0000e-05\n",
            "Epoch 94/100\n",
            "\u001b[1m219/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8622 - loss: 0.3586\n",
            "Epoch 94: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 60ms/step - accuracy: 0.8622 - loss: 0.3586 - val_accuracy: 0.8580 - val_loss: 0.3748 - learning_rate: 4.0000e-05\n",
            "Epoch 95/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 54ms/step - accuracy: 0.8628 - loss: 0.3553 - val_accuracy: 0.8580 - val_loss: 0.3744 - learning_rate: 8.0000e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.8598 - loss: 0.3602 - val_accuracy: 0.8581 - val_loss: 0.3746 - learning_rate: 8.0000e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 49ms/step - accuracy: 0.8604 - loss: 0.3593 - val_accuracy: 0.8581 - val_loss: 0.3745 - learning_rate: 8.0000e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.8603 - loss: 0.3589 - val_accuracy: 0.8577 - val_loss: 0.3745 - learning_rate: 8.0000e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.8629 - loss: 0.3576 - val_accuracy: 0.8585 - val_loss: 0.3744 - learning_rate: 8.0000e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m219/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8607 - loss: 0.3595\n",
            "Epoch 100: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 53ms/step - accuracy: 0.8607 - loss: 0.3594 - val_accuracy: 0.8582 - val_loss: 0.3744 - learning_rate: 8.0000e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# accuracy\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(history.history['accuracy'], label='train_acc')\n",
        "plt.plot(history.history['val_accuracy'], label='val_acc')\n",
        "plt.title(\"Accuracy vs Epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# loss\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(history.history['loss'], label='train_loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.title(\"Loss vs Epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# If train accuracy shoots up but val accuracy flattens or drops, your model is\n",
        "# too big / too complex → reduce layers, reduce units, or increase dropout/L2.\n",
        "\n",
        "# If both curves move up together → you're safe."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 803
        },
        "id": "5zkhk8KcwPGl",
        "outputId": "8035d45f-3573-44b0-9212-fbef83868b61"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiEAAAGJCAYAAABcsOOZAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAegJJREFUeJzt3Xd8k9X+wPFPRpvu0j2gi2HZG8pSUZaAVRQREQFB5aJUgf4cIAKOCzgRF3L1AuoVBFFAREBqAREZZW/KXoUuCt0jTZ7fHw8NxBZoIW2Aft+vV15NTs5zcp5DNd+eqVEURUEIIYQQoopp7V0BIYQQQlRPEoQIIYQQwi4kCBFCCCGEXUgQIoQQQgi7kCBECCGEEHYhQYgQQggh7EKCECGEEELYhQQhQgghhLALCUKEEEIIYRcShAghxG3mm2++QaPRsHXrVntXRYibIkGIEHY0Y8YMNBoNUVFR9q6KuELJl/zVHps2bbJ3FYW4I+jtXQEhqrO5c+cSHh5OQkICR44coW7duvaukrjC22+/TURERKl0+XcSwjYkCBHCTo4fP86GDRtYtGgR//rXv5g7dy6TJk2yd7XKlJubi6urq72rUeV69uxJ69at7V0NIe5YMhwjhJ3MnTsXLy8vevfuzWOPPcbcuXPLzHfx4kXGjBlDeHg4BoOBWrVqMXjwYNLT0y15CgoKePPNN7nrrrtwcnIiKCiIRx99lKNHjwKwdu1aNBoNa9eutSr7xIkTaDQavvnmG0va008/jZubG0ePHqVXr164u7szcOBAAP766y/69etHaGgoBoOBkJAQxowZQ35+fql6Hzx4kMcffxw/Pz+cnZ2JjIxk/PjxAKxZswaNRsPixYtLXTdv3jw0Gg0bN24ssz22bt2KRqPh22+/LfXe77//jkajYdmyZQBkZ2czevRoS9v5+/vTrVs3tm/fXmbZFVXSfh9++CEff/wxYWFhODs7c++997J3795S+VevXs3dd9+Nq6srNWrU4OGHH+bAgQOl8iUlJfHMM88QHByMwWAgIiKC559/nqKiIqt8hYWFxMbG4ufnh6urK4888ghpaWlWebZu3UqPHj3w9fXF2dmZiIgIhg0bZpP7F+JmSU+IEHYyd+5cHn30URwdHRkwYABffvklW7ZsoU2bNpY8OTk53H333Rw4cIBhw4bRsmVL0tPTWbp0KWfOnMHX1xeTycSDDz5IfHw8TzzxBKNGjSI7O5u4uDj27t1LnTp1Kly34uJievToQadOnfjwww9xcXEBYOHCheTl5fH888/j4+NDQkICn332GWfOnGHhwoWW63fv3s3dd9+Ng4MDw4cPJzw8nKNHj/Lrr78yefJkOnfuTEhICHPnzuWRRx4p1S516tShffv2ZdatdevW1K5dmx9//JEhQ4ZYvbdgwQK8vLzo0aMHACNGjOCnn34iJiaGhg0bcv78edavX8+BAwdo2bLlddshMzPTKtgD0Gg0+Pj4WKV99913ZGdnM3LkSAoKCvjkk0+4//772bNnDwEBAQD88ccf9OzZk9q1a/Pmm2+Sn5/PZ599RseOHdm+fTvh4eEAnD17lrZt23Lx4kWGDx9O/fr1SUpK4qeffiIvLw9HR0fL57744ot4eXkxadIkTpw4wfTp04mJiWHBggUApKam0r17d/z8/Bg7diw1atTgxIkTLFq06Lr3LkSVUIQQVW7r1q0KoMTFxSmKoihms1mpVauWMmrUKKt8EydOVABl0aJFpcowm82KoijK7NmzFUCZNm3aVfOsWbNGAZQ1a9ZYvX/8+HEFUObMmWNJGzJkiAIoY8eOLVVeXl5eqbSpU6cqGo1GOXnypCXtnnvuUdzd3a3SrqyPoijKuHHjFIPBoFy8eNGSlpqaquj1emXSpEmlPudK48aNUxwcHJSMjAxLWmFhoVKjRg1l2LBhljRPT09l5MiR1yyrLHPmzFGAMh8Gg8GSr6T9nJ2dlTNnzljSN2/erADKmDFjLGnNmzdX/P39lfPnz1vSdu3apWi1WmXw4MGWtMGDBytarVbZsmVLqXqVtF9J/bp27WrVpmPGjFF0Op2lTRcvXqwAZZYlxK1AhmOEsIO5c+cSEBDAfffdB6h/Xffv35/58+djMpks+X7++WeaNWtWqreg5JqSPL6+vrz44otXzXMjnn/++VJpzs7Olue5ubmkp6fToUMHFEVhx44dAKSlpbFu3TqGDRtGaGjoVeszePBgCgsL+emnnyxpCxYsoLi4mKeeeuqadevfvz9Go9HqL/pVq1Zx8eJF+vfvb0mrUaMGmzdv5uzZs+W8a2tffPEFcXFxVo8VK1aUytenTx9q1qxped22bVuioqJYvnw5AOfOnWPnzp08/fTTeHt7W/I1bdqUbt26WfKZzWaWLFlCdHR0mXNR/vnvOXz4cKu0u+++G5PJxMmTJy33D7Bs2TKMRuMNtYEQlUmCECGqmMlkYv78+dx3330cP36cI0eOcOTIEaKiokhJSSE+Pt6S9+jRozRu3Pia5R09epTIyEj0etuNrur1emrVqlUq/dSpU5YvUjc3N/z8/Lj33nsBdegC4NixYwDXrXf9+vVp06aN1VyYuXPn0q5du+uuPmnWrBn169e3DDuAGsD4+vpy//33W9Lef/999u7dS0hICG3btuXNN9+01K882rZtS9euXa0eJYHjlerVq1cq7a677uLEiRMAlqAgMjKyVL4GDRqQnp5Obm4uaWlpZGVlXbftSvwzyPPy8gLgwoULANx777307duXt956C19fXx5++GHmzJlDYWFhucoXorJJECJEFVu9ejXnzp1j/vz51KtXz/J4/PHHAa46QfVmXK1H5MpelysZDAa0Wm2pvN26deO3337jtddeY8mSJcTFxVkmtZrN5grXa/Dgwfz555+cOXOGo0ePsmnTpuv2gpTo378/a9asIT09ncLCQpYuXUrfvn2tgrHHH3+cY8eO8dlnnxEcHMwHH3xAo0aNyuzNuB3pdLoy0xVFAdR/959++omNGzcSExNDUlISw4YNo1WrVuTk5FRlVYUokwQhQlSxuXPn4u/vz8KFC0s9BgwYwOLFiy2rTerUqVPmKosr1alTh8TExGt2t5f8hXzx4kWr9JK/0Mtjz549HDp0iI8++ojXXnuNhx9+mK5duxIcHGyVr3bt2gDXrTfAE088gU6n44cffmDu3Lk4ODhYDadcS//+/SkuLubnn39mxYoVZGVl8cQTT5TKFxQUxAsvvMCSJUs4fvw4Pj4+TJ48uVyfUV6HDx8ulXbo0CHLZNOwsDAAEhMTS+U7ePAgvr6+uLq64ufnh4eHR7nariLatWvH5MmT2bp1K3PnzmXfvn3Mnz/fpp8hxI2QIESIKpSfn8+iRYt48MEHeeyxx0o9YmJiyM7OZunSpQD07duXXbt2lbmUteSv3b59+5Kens7nn39+1TxhYWHodDrWrVtn9f6MGTPKXfeSv7pLyix5/sknn1jl8/Pz45577mH27NmcOnWqzPqU8PX1pWfPnnz//ffMnTuXBx54AF9f33LVp0GDBjRp0oQFCxawYMECgoKCuOeeeyzvm0wmyxBRCX9/f4KDg20+HLFkyRKSkpIsrxMSEti8eTM9e/YE1ECoefPmfPvtt1aB4N69e1m1ahW9evUCQKvV0qdPH3799dcyt2T/Z/tdz4ULF0pd07x5cwAZkhG3BFmiK0QVWrp0KdnZ2Tz00ENlvt+uXTv8/PyYO3cu/fv355VXXuGnn36iX79+lm70jIwMli5dysyZM2nWrBmDBw/mu+++IzY2loSEBO6++25yc3P5448/eOGFF3j44Yfx9PSkX79+fPbZZ2g0GurUqcOyZctITU0td93r169PnTp1ePnll0lKSsLDw4Off/7ZMv/gSp9++imdOnWiZcuWDB8+nIiICE6cOMFvv/3Gzp07rfIOHjyYxx57DIB33nmn/I2J2hsyceJEnJyceOaZZ6yGkLKzs6lVqxaPPfYYzZo1w83NjT/++IMtW7bw0Ucflav8FStWcPDgwVLpHTp0sPT4gLqDaqdOnXj++ecpLCxk+vTp+Pj48Oqrr1ryfPDBB/Ts2ZP27dvzzDPPWJboenp68uabb1ryTZkyhVWrVnHvvfcyfPhwGjRowLlz51i4cCHr16+3TDYtj2+//ZYZM2bwyCOPUKdOHbKzs/n666/x8PCwBD5C2JXd1uUIUQ1FR0crTk5OSm5u7lXzPP3004qDg4OSnp6uKIqinD9/XomJiVFq1qypODo6KrVq1VKGDBlieV9R1KWz48ePVyIiIhQHBwclMDBQeeyxx5SjR49a8qSlpSl9+/ZVXFxcFC8vL+Vf//qXsnfv3jKX6Lq6upZZt/379ytdu3ZV3NzcFF9fX+W5555Tdu3aVaoMRVGUvXv3Ko888ohSo0YNxcnJSYmMjFQmTJhQqszCwkLFy8tL8fT0VPLz88vTjBaHDx+2LJ1dv359qXJfeeUVpVmzZoq7u7vi6uqqNGvWTJkxY8Z1y73WEt0r77Vkie4HH3ygfPTRR0pISIhiMBiUu+++W9m1a1epcv/44w+lY8eOirOzs+Lh4aFER0cr+/fvL5Xv5MmTyuDBgxU/Pz/FYDAotWvXVkaOHKkUFhZa1e+fS2//uRR7+/btyoABA5TQ0FDFYDAo/v7+yoMPPqhs3bq1PM0rRKXTKEoF+/eEEMKGiouLCQ4OJjo6mlmzZtm7OhVy4sQJIiIi+OCDD3j55ZftXR0hbjsyJ0QIYVdLliwhLS2NwYMH27sqQogqJnNChBB2sXnzZnbv3s0777xDixYtLPuNCCGqD+kJEULYxZdffsnzzz+Pv78/3333nb2rI4SwA5kTIoQQQgi7kJ4QIYQQQtiFBCFCCCGEsAuZmFoGs9nM2bNncXd3v6lTSIUQQojqRlEUsrOzCQ4OLnUG1T9JEFKGs2fPEhISYu9qCCGEELet06dPl3ka95UkCCmDu7s7oDagh4eHTco0Go2sWrWK7t274+DgYJMyhbRrZZA2tT1p08oh7Wp7tmjTrKwsQkJCLN+l1yJBSBlKhmA8PDxsGoS4uLjg4eEh/7HYkLSr7Umb2p60aeWQdrU9W7ZpeaYzyMRUIYQQQtiFBCFCCCGEsAsJQoQQQghhFzIn5AYpikJxcTEmk6lc+Y1GI3q9noKCgnJfI67vRtrVwcEBnU5XyTUTQghxPRKE3ICioiLOnTtHXl5eua9RFIXAwEBOnz4te4/Y0I20q0ajoVatWri5uVVy7YQQQlyLBCEVZDabOX78ODqdjuDgYBwdHcv15Wc2m8nJycHNze26m7eI8qtouyqKQlpaGmfOnKFevXrSIyKEEHYkQUgFFRUVYTabCQkJwcXFpdzXmc1mioqKcHJykiDEhm6kXf38/Dhx4gRGo1GCECGEsCP5NrxBEkjcvmQ4TAghbg3yTSqEEEIIu5AgRAghhKgGFEVh64kM0nMK7V0VCwlCxA0JDw9n+vTp9q6GEEKIcjhwLov+X23isZkbue+DtXy38QQms2LvasnE1Oqkc+fONG/e3CbBw5YtW3B1db35SgkhhCilqNjMoZRsvF0dCfRwQqu9sblsF/OKmBZ3iO83naQk5sguLGbiL/v4edsZJj/ShMY1PW1Y84qxexDyxRdf8MEHH5CcnEyzZs347LPPaNu27VXzT58+nS+//JJTp07h6+vLY489xtSpU3FycrLkSUpK4rXXXmPFihXk5eVRt25d5syZQ+vWravilm5biqJgMpnQ66//a+Hn51cFNRJCiNvP3qRMEpOzaVLLk3r+bhWeDL/haDpvLN7LsfRcABx1Wmp6OVPLyxkfV0c8nR3wdHbAw9mBYrPChdwiMnKLuJBXRFZBMWazQrFZwawonDyfR2a+EYDeTYIY27M+axJTeX9lIrvOZPLQ5+sZ2jGC2G534Wqo+pDArkHIggULiI2NZebMmURFRTF9+nR69OhBYmIi/v7+pfLPmzePsWPHMnv2bDp06MChQ4d4+umn0Wg0TJs2DYALFy7QsWNH7rvvPlasWIGfnx+HDx/Gy8ur0u5DURTyjdferdNsNpNfZEJfVGyzlTXODrpy/3I//fTT/Pnnn/z555988sknAMyZM4ehQ4eyfPly3njjDfbs2cOqVasICQkhNjaWTZs2kZubS4MGDZg6dSpdu3a1lBceHs7o0aMZPXo0oK44+frrr/ntt9/4/fffqVmzJh999BEPPfTQdetmMpkYPnw4q1evJjk5mdDQUF544QVGjRpllW/27Nl89NFHHDlyBG9vb/r27cunn34KwMWLFxk3bhxLliwhMzOTunXr8u677/Lggw+Wq32EEPajKAqbj2dwMc9Ih7o+eDjd3OmtBUYT2QXFZBUYMZkV6vi5obtKT0JWgRFHnRYnh+sv1y82mdl0LIP4gym4OuppXNOTJrU8CfZ0IjPfyJIdSfy49Qz7z2VZrvFxdaRdbR+ianvTKsyLyAB39LqyvwPO5xQy+bcDLNqRBKj/jy8ymSkymTmensvxS0FJRUUGuDPpoYZ0qOMLwOD24fRoFMjby/bz2+5zfLPhBI+1qkWDINucGl8Rdg1Cpk2bxnPPPcfQoUMBmDlzJr/99huzZ89m7NixpfJv2LCBjh078uSTTwLqF+GAAQPYvHmzJc97771HSEgIc+bMsaRFRERU6n3kG000nPh7pX5GWfa/3QMXx/L9E37yySccOnSIxo0b8/bbbwOwb98+AMaOHcuHH35I7dq18fLy4vTp0/Tq1YvJkydjMBj47rvviI6OJjExkdDQ0Kt+xltvvcX777/PBx98wGeffcbAgQM5efIk3t7e16yb2WymVq1aLFy4EB8fHzZs2MDw4cMJCgri8ccfB+DLL78kNjaWd999l549e5KZmcnff/9tub53795kZ2fz/fffU6dOHfbv3y97gAhxi9iblMmPW08TXMOZdrV9aBzsgV6nJaewmEXbz/DthhMcTVO/YPVaDW0jvOnSIID7Iv0I93EtNRRxOiOP5XvOsWLvOU6k6Pj3nrWYFDCazBQa1S/tK/m5G+jeMICejYNoV9ubc5kF/L4vmVX7U9h6IgMXRz3P3V2bZ+6OwO0fvQHFJjMJJzL4bfc5Vu5N5nxuUan783Z1JKewmKJi9XMddVoaBntwMDmL87lF/LbnHL/tOQeogUXTWp40D62Bt4sj+UYTBUYzeUXFLN11lot5RjQaeCoqjJd7ROLqqONcZgGnL+Rx5kI+F/OKyMovJjPfSGa+EZ1Wg7ero+Xh7qRHr9Wi02rQazW4OOpoFeZVKvAJ8HDiiydb0q9VKodTcuwSgIAdg5CioiK2bdvGuHHjLGlarZauXbuycePGMq/p0KED33//PQkJCbRt25Zjx46xfPlyBg0aZMmzdOlSevToQb9+/fjzzz+pWbMmL7zwAs8999xV61JYWEhh4eXZwllZahRrNBoxGo1WeY1GI4qiYDabMZvVX7iSn1Xtyjpcj7u7O46Ojjg7O1t6mfbv3w/Am2++SZcuXSx5a9SoQZMmTSyv33rrLRYvXswvv/zCyJEjLekl7VBiyJAh9O/fH4B///vffPrpp2zatIkHHnjgmnXT6XRMmjTJ8josLIwNGzawYMECHnvsMUt5sbGxvPjii5Z8rVq1QlEU1q5dS0JCAvv27eOuu+4C1AC1pI3+yWw2oyiKbFZ2FSW/8//83Rc3rrq2qcms8N/1J5gef4TiKyZBuhp0NKvpye6kLHIKiy1pAe4GjqXnseHoeTYcPc87y8DFUUcdP1fq+rsR5OHE30fPs+tM5hWfooGi0oGBRgNuBj0ms0JadiFzN59i7uZTuDjqyCuy7rnOKSzm4z8O8e3G4zx/b22imwax+VgGqxPT+PNQOhfzL/+7ebk40K2BPwqwNymLw6k5ZFwKTOoHutOvVU0eahpEDRcHiorN7EnKZPPxCyScuMCuM5nkFBaz+XgGm49nlNlmDQLdefuhBjQPqQGAYjYR6O5AoLsnbUJvbO6GYjZhNJfdW9+xthcda3uV+h29md/VilxrtyAkPT0dk8lEQECAVXpAQAAHDx4s85onn3yS9PR0OnXqZDlAbsSIEbz++uuWPMeOHbP81fz666+zZcsWXnrpJRwdHRkyZEiZ5U6dOpW33nqrVPqqVatK7Yqq1+sJDAwkJyeHoku/+IqisDG2XYXu3xaM+blkFZR/rLG4uJiioiJLkFVy9k1kZKQlDSAnJ4f33nuPVatWkZycjMlkIj8/n8OHD1vymc1mCgoKrK6rW7eu1Wt3d3dOnTpllXY1X3/9NXPnzuXMmTMUFBRQVFREkyZNyMrKIi0tjbNnz9KuXbsyy9qzZw/BwcEEBgaW67OKiorIz89n3bp1FBcXXzd/dRUXF2fvKtxx7oQ2NSlw8KIGg04h1BUcrxLHZxTC94d1HM1W/x/VsIYZnQaOZGnILTSx4Zj6JezvpHB3oJm2fsU46QtJD4G9FzTszdBwLFtDXpGJPUlZ7Em6/N+2BoW6HgrNfRRC3BR0GiwPvRacdWDQgVZTTLEZDmdq2JWhYXeGhtwiExoU6nhAE28zTbwUTuZoWH5aS1qukcnLE5m8PNHqXlz0Ck29FVr4KNTzKEanPQlApwgwhsHZPHDQQrDLBci4wIa1e62uDwfC/eExP0jNhxM5Gk7laCgyg6NWvdZRC35OCq38LnB2zwbO7rHNv9eNupnf1Yqcq2b3iakVsXbtWqZMmcKMGTOIioriyJEjjBo1infeeYcJEyYA6pdj69atmTJlCgAtWrRg7969zJw586pByLhx44iNjbW8zsrKIiQkhO7du+PhYd1FVVBQwOnTp3Fzc7OaDHu9+FRRFLKzs3F3d7fbjp16vR5HR0fLPZUEWIGBgVb3+dprr/HHH3/w/vvvU7duXZydnXn88cfRaDSWfFqtFicnJ6vrPDw8rF5rtVqrz7ua+fPnM3HiRD788EPatWuHu7s7H374IQkJCXh4eFjay8XFpVRZiqLg7OyMVqu97ueUKCgowNnZmXvuucfq31CojEYjcXFxdOvWDQeHmxubF6o7pU03HD3Pv5cf5HCqOnTioNPQMMiDVqE1CPR0IrvAeGkuRjGr9qeSU1iMq6OOCb3r82iLYDQaDSazQmJKNjtOZxLq7UzH2j5XXflRbDJzMiOfw6k5HEnN4fSFfJrU9KBHwwD83A0Vbtdik5nElBwCPZ3wcXW0eu81k5lFO87y2ZqjpGQVUtvXlfvr+3F/pB8tQjyvOo/jTmOL39Xy/DFYwm5BiK+vLzqdjpSUFKv0lJQUAgMDy7xmwoQJDBo0iGeffRaAJk2akJuby/Dhwxk/fjxarZagoCAaNmxodV2DBg34+eefr1oXg8GAwWAole7g4FDqH8FkMqHRaNBqtRWaYFoyLFByrT04OjpiNpstn3/lzyvrtGHDBp5++mn69u0LqD0jJ06coHPnzlb5/nkvZbVJedpp48aNdOjQwWqo59ixY5brPT09CQ8PZ82aNVbDRqC2a6NGjThz5gxHjhyxDMdci1arRaPRlPnvKy6T9rG927VNT2fkMfm3A6zclwxADRcHHHVaUrML2XUm8x/DI5e1DK3Bx/2bE+ZzeTm/A9As1IdmoT7X/VwHB6gfbKB+cI3r5Ctfuzo4QPOw0v+vL3nvqfYR9G8bRma+EV+3svPd1oqL4OR60OqhRhh41ARd2WHAzfyuVuQ6uwUhjo6OtGrVivj4ePr06QOoXyjx8fHExMSUeU1eXl6pL7SSMX1FUccbO3bsSGKidVfaoUOHCAsLs/Ed3H7Cw8PZvHkzJ06cwM3N7arzSerVq8eiRYuIjo5Go9EwYcKESp33Uq9ePb777jt+//13IiIi+N///seWLVusJhS/+eabjBgxAn9/f3r27El2djZ///03I0eOpGPHjtxzzz307duXadOmUbduXQ4ePIhGo7nufBQhxNUVGE3MWHuUmX8epajYjE6rYVC7MMZ0vQsPZz1nLuSz9WQGW09cIKugGA8nPe5ODrg76QnxdqFX48DbrgfBQae9NQKQnFTIOA7Klf/vVaC4AIwFYMy79Dz/8qM4H3SOENgUarYE9yB1ckxaImz/DnbNh7z0y8Vp9Wog4hUGj/4X3ANKVaOy2XU4JjY2liFDhtC6dWvatm3L9OnTyc3NtayWGTx4MDVr1mTq1KkAREdHM23aNFq0aGEZjpkwYQLR0dGWYGTMmDF06NCBKVOm8Pjjj5OQkMBXX33FV199Zbf7vFW8/PLLDBkyhIYNG5Kfn2+1guhK06ZNY9iwYXTo0AFfX19ee+21CnWvVdS//vUvduzYQf/+/dFoNAwYMIAXXniBFStWWPIMGTKEgoICPv74Y15++WXLHjElFi5cyKuvvsqAAQPIzc21LNEVojpTFIW0nEL83Ss27KgoCnH7U3h72X7OXMgHoEMdHyZFNyIy0N2SL8TbhRBvFx5pUcum9b6jFRfB2R1wehMUZoPWAbQ60DlA3nlI3gspeyEn5fplXY9bALj6Q8oe6zSDO1w8BaYiuHhSfRjcr15OJdIoJV0IdvL5559bNitr3rw5n376KVFRUYC6w2d4eDjffPMNoE6snDx5Mv/73/9ISkrCz8+P6OhoJk+eTI0aNSxlLlu2jHHjxnH48GEiIiKIjY295uqYf8rKysLT05PMzMwy54QcP36ciIiICs0nMJvNZGVl4eHhISfw2tCNtOuN/htWF0ajkeXLl9OrV6/bcujgVmSPNs0tLOb5udtZdyiN3k2DmBTd8JrBSHaBkeTMApIu5vPthhOsSUwDIMjTiTd6N6RXk8Dyz2czGaEgC5w8r9rdf9PMJoznTxC3bjPdHupX/nY1m9RehCt7E8z/mKCu1YOzl/rQXSrXbFZ7ETLPQHYyuAdCYJPL75cw5kPSNkg9oLaD2aiWX5gDZ7aoj+KCclRUAzVC1J6NK+md1IeD8+WfDi6Xfjqr7X5up/r5yqUVMRod3NUDWg6Gut3UfxOzGXKS4cIJyDoLTdQ/6mzxu3qt79BSd2nvIORWJEHI7UOCENuTIMT2qrpNL+YVMfSbLew4ddGS5uGkZ3zvBjzeOgSNRsOp83ks33uO3/clczglx7JUtoSDTsOzd9fmxfvrXn0/IrMZzh9Wv1hTD8D5I+rjwonLX+wGT3DxUv8Cj/oXNO5bupyCLFgzRe0dMBWr15ovLfN0qgEu3uDio/61npl06TOOg6kIBQ34N0AT1hHC2qtzHS6eUv+6v3ASspLUHoa8DMjPgIKy569clcEDHN3UAMT0j6XAemcIbgEhbdQv+pMb4Oz20vn+ycUHQturQyFm46VgpVgNJgIbQ0ATCGgIjjdxNEZRntqjcuEkRNytBk3lUNVByG21OkbcnkaMGMH3339f5ntPPfUUM2fOrOIaCXH7OXAui0Xbz2DQ6wjwMODv4USAhxO1fZ3xSN8FB5fBweUUFxeyrKADyZkd8XQOZMKDDflmw3H2JmXx2s97+HHrGQqMJvadLT3E6unsQJCnE5GB7rzUpR51/NxgyyyIm6j2CngEqw+3ADUQOLMVCi5eu+KFmerjwgk4vRkOLIPeH6mBBcCJ9bDkeTVwqCBF54jGVASp+9XHlq8rVoDeGRyc1CGRK5kK1cAIBQqz1AcAGvXe3QPU+ynIhFMb1MeV3ALVORkOLmpPiVYPegMENIawjuBbT52rUZkcXSCkrfq4hUkQIird22+/zcsvv1zme+VdVitEZSnpDC7vUENmvpEFW07RKkzdhrss2QVGjqXl4uXiiK+7Iw7/KNpsVo96cHbQXfdgsrMX85kWd4ift5/hyn5rA0X8n34hQbq/8dBctKTrgac4xQCnH8kL64a753D6PH8fczacZFrcIbadvACATquhXW1vejUJIirCmyBP59Jnhxz/C5a/onbrF+VA5unSFSzpDQhqBr51wace+NQFN3/1S7qkB+LIH/DXNNi3SO0xeHCa+nPjF4ACNULh/olqr4n20hc3CuRfVK/Pu9SL4R4EPnXApy7FLgHE//ojXSPd0J/ZrJaXmwaeIeAVrk649AwBV19w9lYDH2dvMLiBzgDX6j01my5/dmEWuPqpn33l8Mz5w3A6Qe0JUkxq70ZYB/CKqPwg4w4hQYiodP7+/mWeBSRElVIU2DYHNs6Ats9xvM5TzNt8kp+3J5FTWIyfmwFfdwN+bgbqBbgxqF0YwTWcrYr463AaryzcTXKWOqbfu2kQY7vXIyT9LyjKIcunGV/vVfhmw0myrxjecHbQYtDoeHv3WvKKTJazpiwHk9VwIryGDm8PD9ydHfBwcsDDWc+uM5nMXn+cwkvbgfdoFECAhxMZFzN55swbtDBuByBbcWaNuTm/m9qgxcwwp7W0MO/F/cTvcOJ39Hf15LnoT3ig8T0svLR9ereGAfjo8tSejtN+4DvI6l7JPAMLn1a/XJv0g6gRalrWWcg+B561oFabsudFlHD1VR8Aoe0gsicsHgHph2D+k5fztRwMPaZUfHKk0UihgydK/V7Q5NGKXXs9Wh24+qiPMt/Xgl+k+mg5qOw84rokCBFC3PmyzsHSGPWvcYAVr/K9cTezTL0sWZIu5pN0MZ+apJF0MI+v14XTp0VNRtxbh+AaTkxdfpD/bVJ3yvR3N3A+Jx/93oUYE5eA5iwAHsAQxYOm5rpscW7J/4z3k18M+UYz+VdsL+7HBaY4zCJScxq37Hzcs/NxOGPiiDmYZ43/xwklyKr6bcO9GderPi1CvdSx/h+eAON2cHAls8cnJDhGsT8pj7RTF3By0FGz3wQoOAlbZ6uPQytgxmZCHvyY2O591MmTCTPVnomS4ZR9i6HPl+ARpE7aXDBInQcR2ASiP1W792vd5EnkNVvBv9ZB/NuwaYY6tPHQZ+qkSVEtSRAihKhyJrPCusNpNKnpaZM9GXIKizmdkcfpjDx0Wg2Ngj0J8DCoQyx7fsK87P/QFl6kEAf+NDWlu24bExy+p3ZADYK6v0Q9f3fSM7Nx3/o5Efu/RKMU82TReH7apvDz9jP4uDqSnqMGEEPahfJ62H5Y+x6GzKMAXFDcOKEE0lBzAl9NFt102+mmbGfcvW7k3jOB5Au5LI9fS5d778bDoCNwST8ckraXuo+62rP84jKZ9/3f56C5Jo46Lc90iqBLA3/1Xgpz1ADkxF/qZMmBC/EM60A3oFvTfxTmHgk931N7GRb/C5L3wMIhsLsXnNulTtgEdfgk8wwcWwNftofoT+BwnDrB0tkL+n+vBiC24uAMD0xVe1ZcfNShEVFtSRAihKhSGblFxP6whdNH92F0D2XuiHsI8b72l9zpjDx+35fMpmPnyS00UWw2Yy4uokH+dgryczmd78wF3LiguOGjyaal9jDtHY/SWneEoOIzaIHd5ghijc9z0SUCj8BltEv6loEZn0NOHXBvRsiKFyF1n+Uzv/GdyxjvGaw4eIH0nCICPZz4oF9T7k6dB79MBEBx9uJo3aG8cioKs4MbI+8JpavnObRH42DdB2j+no5bQGPCGvQhzA3uCnDHYfWbkLRZXXXRbw541FKHIczFMP9JPFP2MjnzNRi0BIKuiCwyjsGSkeokSEd3eOpnCI26foMHNIJnV8Of78H6aZC4XE33qAX3j4em/eH8UVj0rBqc/DhYfV+jhb6z1LkVlcFLNpAUEoQIIapCUS7sX0pq4gZSD27kP+YTGAxGdhbUZvhXbzFrRLdS8y/S9//J0U3L+CPDh6XpNUlBXU1RS5PGE7rV9NetxU9zabllWZ0pClAMRkXH58V9SAgZyqj2dejRKBBHXTeI84ANn8GyMeoXrmJW/zLv+iasnoxT1nG+bBbPoZ6j2Xw8g4eaBeOZth3+uHTYZcdRaO5+mbpOHiy2+uBQCItSg4r1H8PSGDSe6heu5uAy2Pi5mu3hL6BuV+s6D/kVvn9U3czq2wfVIOD8UdizEJK2XrpXTxi0qGJDI3pH6DJBnZPx1zR18mSbZ9WVIQB+d8Ezf8DaqWqdUeD+CVC3yzWLFeJmSRAihKhcWWdR5j6GJmUf/oA/wKWFA821x/ggbwIjvlL4ekQPAjycyMwrImH+FO4/OZ0ojUIUMN4J0nV+FLvVIiBzJxrUZSKFzv6YPEIwGC+iy7+gzm9wcMEU1JJUz6bs00Vy2LEBvVrUZ0zgPyY9dntH3ZNi85dqANKkHzzwrjqR0qkG/DgI/p7OXY37cle7hurqjJ+GqRM1Gz8GXd+69gqI+ydAyn44/Du6nwbjEzgU3a+fqu+1j4GGD5W+xsUbBv8Cc/upy1nnXt4VGI0WandWPzfon2Mv5VSrNQyYV/Z7ekfoOgkaRKvLZRs+fGOfIUQFSBAiyi08PJzRo0czevRoe1dFVJbc8+h+HU3HM4mQEQkB9UvnyctQV5lcOKGeb5GTqi6L9G9AYafXSNTV5cC5LA6n5FB8bg8vnH0dfyWdNMWDxaa70dVqQf+HH8JNW4zpm2ga55/g3ZwJjPgP9Godifefr9OXeNDAbsfmhDjlUyP7ML6mNMhUd/Gk9n3QehiGyJ7WKzMunXGk02oJAoKArv+sfwmNRp2bULOVupy09r2X32sQDZG9IfE3+PUlGLpSXdWRdQa860D09OsvwdTqoO/X8N+uaNIP0SlbPdmb0A5qb8vVOHnCU4vU1SPH/1RXoDTpB40eUetZ2Wq2VB9CVAEJQoSoTo6thaUvqcMAnceBmx/H03NxcdQRkL0PfhyCNvM0voAyuxv0/a/1yoWja9SNpbLPlS478zSGw6s4aWrHjOLHCdWkMsPhE9w1+Rw21+QFxvLEA3czrGO4ZU8O3dDlmL55kIZ5J5maPZ4Lq91pr9uPGQ3Hmo+lyUOvotFq1TM2krZDxlGIuFfdJ6IsFd2NWKOBpv3KTu/1ARxfp+4B8W20OhdDZ4DHvy3/UlInTxgwH+Xr+9AUZKK4+qPpN+fqS1pLGNzUOSEFFy9v6iXEHUiCECGqi+Ii+HW0up311lkYd85nnuNjTMm4j766v3jT4VscKSbHNYxcswMB+UdQ5vXHeM9YtB1eRP/nFMt8BsW7LokBPVlzRsO28w5kKy7016+hj/ZvonWb6KnbggbQYeJiQBTOD3/DysAgdP/cmMu/Prqhyyme8yD189SNsIx6V7SPzaJu/Z6X8xnc1Z6KK3srKptnTXV4YvnLl3fE7PmuumS1InzqYHp8Lmm/TMTvkXfRl3P7bLRaCUDEHU8OMbEFRVEn3l3vYcwrX77yPipw7M9XX31FcHAwZrPZKv3hhx9m2LBhHD16lIcffpiAgADc3Nxo06YNf/zxxw03ybRp02jSpAmurq6EhITwwgsvkJOTY5Xn77//pnPnzri4uODl5UWPHj24cEHdzdFsNvP+++9Tt25dDAYDoaGhTJ48+YbrI4At/4ULx8nWe7NPqY1DcS5D8r5li+EFpjjMwpFiVpra0P78BDpdmMj/iruiQcFx3VRyptazBCALNd2JypjIAzva815aO/7UtCawWRc8n5xNxqB4lLrd0GNChwmaPE6N536lVnBw6QCkhN9d6J9ZgeJdG8WnHg7P/YHuygDEnlo/A7UubXvduC+0GnpDxSgh7UioPRpFhjmEsCI9IbZgzIMpwdfMogVq2PpzXz9b7gOO+vXrx4svvsiaNWvo0kWd8Z6RkcHKlStZvnw5OTk59OrVi8mTJ2MwGPjuu++Ijo4mMTGR0NDQCldNq9Xy6aefEhERwbFjx3jhhRd49dVXmTFjBgA7d+6kS5cuDBs2jE8++QS9Xs+aNWswmdSdJMeNG8fXX3/Nxx9/TKdOnTh37hwHDx6scD0EFJvMrNl5iParJuMGTM5/lAWmzjzruY1R/IBHYTKKRsuhxrFs0j9CwJF0Tp7PYZJpGHuUCN7Rz6GGJpd0xYNXjcNZbVa/SP3cDQyMCuXJtqH4e5QcBBgAdX+CkxvVIZtGj5Rv+2qfOmhitqqTL2+l7a61WnhinrrZV5N+t1bdhLgDSBBSTXh5edGzZ0/mzZtnCUJ++uknfH19ue+++9BqtTRr1syS/5133mHx4sUsXbqUmJiYCn/elZNXw8PD+fe//82IESMsQcj7779P69atLa8BGjVqBEB2djaffPIJn3/+OUOGDAGgTp06dOrUqcL1qI6KTWaOpOWw+0wme85k8seBFIbmzqKbPodEcwhZ9fszt31t2tV+EK3pNdizEI1fAyJD2vAm1qdoarQ9MSYNID9xFeZGA5lk8GFssRmjyUw9f3cc9VfpTA1rX/GKa3U3c9uVx81P3fBLCGFzEoTYgoOL2itxDWazmazsbDzc3ct95Hy5PrcCBg4cyHPPPceMGTMwGAzMnTuXJ554Aq1WS05ODm+++Sa//fYb586do7i4mPz8fE6dqvjJlgB//PEHU6dO5eDBg2RlZVFcXExBQQF5eXm4uLiwc+dO+vUrY0IgcODAAQoLCy3BkiiboiisTUzjQHIWyZkFnMss4FxmPkdTcy1nkwCEaFJ42vA7AH5932NGsytO1dQ6X/MLVq/Tog9tBaGtcL5qLiGEuDEShNiCRnP9YRGzGRxMaj5bBSEVFB0djaIo/Pbbb7Rp04a//vqLjz/+GICXX36ZuLg4PvzwQ+rWrYuzszOPPfYYRZfOuqiIEydO8OCDD/L8888zefJkvL29Wb9+Pc888wxFRUW4uLjg7Hz1r7RrvSdUJrPCG0v28kNC2UGim0FP45oeNK1Vg6Fn/4fjmWKofR/eTXuVmV8IIexBgpBqxMnJiUcffZS5c+dy5MgRIiMjadlSHd//+++/efrpp3nkkUcAyMnJ4cSJEzf0Odu2bcNsNvPRRx9Zen1+/PFHqzxNmzYlPj6et956q9T19erVw9nZmfj4eJ599tkbqsMdqTAbDvyK0bcBr/xlZsmuZDQaiG4aTIiXgSZKIg0vrMVLycLNJwiNe4A6xyJhBaCB7v+WOQ1CiFuKBCHVzMCBA3nwwQfZt28fTz31lCW9Xr16LFq0iOjoaDQaDRMmTCi1kqa86tati9Fo5LPPPiM6Opq///6bmTNnWuUZN24cTZo04YUXXmDEiBE4OjqyZs0a+vXrh6+vL6+99hqvvvoqjo6OdOzYkbS0NPbt28czzzxzU/d/W1sxFnZ+jwMwXvHgPocmhLV+gOaO62DfL9Z7dxz+x7UtBkJg46qsrRBCXJcEIdXM/fffj7e3N4mJiTz55JOW9GnTpjFs2DA6dOhgCQKysrJu6DOaNWvGtGnTeO+99xg3bhz33HMPU6dOZfDgy3MP7rrrLlatWsXrr79O27ZtcXZ2JioqigEDBgAwYcIE9Ho9EydO5OzZswQFBTFixIibu/nbWU4qyp4f0QB5igE/TRYP6/6GHX9fzmPwhPq9wL+BuoNpTirkpIDOEbpMslvVhRDiaiQIqWa0Wi1nz5aeRBseHs7q1aut0kaOHGn1uiLDM2PGjGHMmDFWaYMGDbJ6fe+99/L3339TFq1Wy/jx4xk/fny5P/OOtu0bNKYidprr8DRv830PDY3ztsKpTepppI0eUc8V0Zd1kpsQQtyaJAgR4lZXXISy5b9ogNnFD/DW4y1o3Lwm0NveNRNCiJsiO6aKCps7dy5ubm5lPkr2+qh2krbBxdOVU/b+X9DkpJCi1CBe054uDQIq53OEEKKKSU+IqLCHHnqIqKioMt9zcLjOwVx3oqTt8N+u6umqMVtsvwJl85cAfF/clZa1/XEzyH+2Qog7g/zfTFSYu7s77u7lPEW0Otj8H1DMcP4wpB1UJ4baypmtkLQNIw78YOrCi9ILIoS4g8hwzA1SKnB4nLi12PTfLjcd9i26/PrwKtuVDbBJ7QVZampPOp7cX9/ftuULIYQdSRBSQSXDDXl5eXauibhRJbvA6nQ2OKtk+3dgKlI3BQM4HHfzZZbIOgf7lwAwu7gHkQHuhHhXbKt+IYS4lclwTAXpdDpq1KhBamoqAC4uLmjKMQfAbDZTVFREQUGB7c6OERVuV7PZTFpaGi4uLuj1N/nrbzbB1jnq87tfhnXvw6mNUJAJTp43VzbA1tlgLuaocxP2FUTwfAPpBRFC3FkkCLkBgYGBAJZApDwURSE/Px9nZ+dyBS2ifG6kXbVaLaGhoTf/73Dod8g8Bc5ecHcs7Fuszgs5thYaPlxWZSH/wuVNxPIvQMQ94OJdOm/mGctQzIz8rgB0lSBECHGHkSDkBmg0GoKCgvD398doNJbrGqPRyLp167jnnnuq5wqSSnIj7ero6Hi51+TiKfjhSfCpDT2mgGet8n/4lq/Vny0GgYMz1OuuBiGHV5UOQrbMgt9fh+IC6/TAJjBsFTheMcyiKPDraCjKJtu3BYvPtMLLxYHmIV7lr5sQQtwGJAi5CTqdrtzzCnQ6HcXFxTg5OUkQYkM33a6rJkDKHvVxJB7ufwPaDgftdf5d04/A0dWABtpcOs+mXjfY9AUc/kMNJEp6WvIvwh9vXQ5AnGqAWwBkJ0PyHlgaA31nXc6/6wc4Egc6A/OCXsN8xsx9kf7otNKDJoS4s8jkBFF9ndqkTvzUaCG4JRTlwMqx8N8ucGgVnNsFGcfUFTCmf/R4bZ2l/qzXHbzC1edhHcDBFXIuBRclNn4BhZng3xDGp8DYkxCTAAN+AK0e9v4MGz5V82Ynq3UA6DyWH084A8gGZUKIO5L0hIjqyWxWh0dAHU55cDps/wbi3oSzO2BeP+v8Gp0aRAQ3Vx875qrpbZ+7nEdvgNr3QuJydUgmqCnkZVjmdtB5HDg4Xc4f3hEeeBeWvwx/vAkBjWDLbHVia1BzTkQ+w9Hf1qPXarj7Lt/KaAUhhLAr6QkR1dPen9Wt1h3d4L7xoNVC62FqD0XzgeAbCe7B6vsAikkdstnxP/jt/9SeDa8IqNPFutx63dSfJUt1N3wGRdnq3I/6D5auR5tn1SBIMatzUxJ/A60D9JlB/KEMAKJqe+PhJEN4Qog7j/SEiOrHmK/2PAB0GgPuVwx1uAdCnxnW+c0myD4HZ3eqvSRnd6jDNF3fVIOXK9W9FIScSYD0w+puqgCdXy+dF9R5IL0/UndaPbMFgJx2Y5h70InZfx8F4P76MhQjhLgz3RI9IV988QXh4eE4OTkRFRVFQkLCNfNPnz6dyMhInJ2dCQkJYcyYMRQUFJSZ991330Wj0TB69OhKqLm4LW38ArLOgEctaD/y+vm1OnXVTIMHocsEGLQIRu2ERn1K560Rog7bKGYuzO4HxlwIag6RPUtlPXk+ly0nMlhzNJO4Jh+S5RrOQUNTWq9twtQVB0nJKiTAw0B006CbvWMhhLgl2b0nZMGCBcTGxjJz5kyioqKYPn06PXr0IDExEX//0vsizJs3j7FjxzJ79mw6dOjAoUOHePrpp9FoNEybNs0q75YtW/jPf/5D06ZNq+p2xK0uJxXWf6w+7zpJXVprQwVGE5vMzenMfrzyjgOwLzKGRlfsSXIwOYv3Vyay+uA/95mZYnnWMrQG/VqH8GDTINxlKEYIcYeyexAybdo0nnvuOYYOHQrAzJkz+e2335g9ezZjx44tlX/Dhg107NiRJ598EoDw8HAGDBjA5s2brfLl5OQwcOBAvv76a/79739X/o2I28OmL9VVMMEtofFjNi365Plcnv9+O+7JdehsUNO2m+vy6Epn+qbu4plOEcz++zg/bz+DooBOq6GWlzOujnrcnPS4GfREBrrTt2Ut6vq72bRuQghxK7JrEFJUVMS2bdsYN26cJU2r1dK1a1c2btxY5jUdOnTg+++/JyEhgbZt23Ls2DGWL1/OoEGDrPKNHDmS3r1707Vr1+sGIYWFhRQWFlpeZ2VlAepGWOXdjOx6SsqxVXlCVapdL5wAnQN41Cwzvz5xBRqguO2/UEwmMJmu/xkmM0kX89FpNTjqtBj0OvQ6DXlFJrLyjWQXFnM0LZcpKxLJLijG36UhRn0NHIousrvuC2gOaPh5+xl+3n7GUuYDjQKI7VqXCF/Xa96XPcjvqu1Jm1YOaVfbs0WbVuRauwYh6enpmEwmAgKsJ94FBARw8ODBMq958sknSU9Pp1OnTiiKQnFxMSNGjOD111+35Jk/fz7bt29ny5Yt5arH1KlTeeutt0qlr1q1ChcX2x4YFhdnwwPOhEVcXBxeuYfpeHgqRp0LcY2mYdY6WuVxLkqne9oBFDSsOmrCeHL5NctML4CNKVoS0jRkGcu3UViEu8LT9YrZWDwKJ2MGXp6+jG5UzPyjOs7la6jjrvBQmIlw9yQOJCRx4IbvuPLJ76rtSZtWDmlX27uZNq3IAa92H46pqLVr1zJlyhRmzJhBVFQUR44cYdSoUbzzzjtMmDCB06dPM2rUKOLi4nBycrp+gcC4ceOIjY21vM7KyiIkJITu3bvj4eFhk3objUbi4uLo1q2b7JhqQyXt2r1dI5y+exmNUoyuOIue9RxRIntZ5dVumwP7QAmJottDj5dZntmssOpAKvMSTrPxWIYl3aDXotFAUbEZs3KpPA24O+lxN+hxd3Lgvkg/Yu6rjYPu8nzvFpd+DjeZOXMxnzDv8h14aE/yu2p70qaVQ9rV9mzRpiWjCeVh1yDE19cXnU5HSkqKVXpKSorlkLh/mjBhAoMGDeLZZ58FoEmTJuTm5jJ8+HDGjx/Ptm3bSE1NpWXLlpZrTCYT69at4/PPP6ewsLDUVusGgwGDwVDqsxwcHGz+i10ZZVZ3WnMRhsXD0OSmqrufKmb0B3+Bxv84v+XYajX/Xd3R/uPfwGRWWLb7LJ+vPsLh1BxAXT17Tz0/nmgTQpcGATjq1eCi2GTGaFJwctCWO6BwcIB6gaV/x25l8rtqe9KmlUPa1fZupk0rcp1dgxBHR0datWpFfHw8ffr0AdSj1uPj44mJiSnzmry8vFJHtpcEFYqi0KVLF/bs2WP1/tChQ6lfvz6vvfZauc96EbcJRaHFqf+ivbALnL2h94fw0zBIXAlFeZcPhjMWwPE/1ef1uqMoCmk5hZzOyOdgchaz/jrOsfRcADyc9AxuH84TbUOo5VV6OE6v06KXXyMhhLhpdh+OiY2NZciQIbRu3Zq2bdsyffp0cnNzLatlBg8eTM2aNZk6dSoA0dHRTJs2jRYtWliGYyZMmEB0dDQ6nQ53d3caN25s9Rmurq74+PiUShe3MEWBhK/UXU1D26tH3nvXvnzI26U82o2fUuvCJhStHs3j30F4J3Ujsoun1EPgSk6zPbkejHnkGfx59IcMTmSspMBotvrIGi4OPNspgsEdwmWHUiGEqAJ2D0L69+9PWloaEydOJDk5mebNm7Ny5UrLZNVTp05Z9Xy88cYbaDQa3njjDZKSkvDz8yM6OprJkyfb6xaErSmKGkj8PV19vXuB+tMzBGq2VE+lzUqCrLPojOoEKHP3Kegi7lbzNXoE/v4E9i22BCHpO5bhC/yS24iDmepwi1YDQZ7O1PJypnOkP4Pah+FmsPt/EkIIUW3cEv/HjYmJuerwy9q1a61e6/V6Jk2axKRJk8pd/j/LELcwRVFPkd08U33dfKC67PZ0AmSeVh9XZkfDEf9ehLcahmWEpCQIOfQ75zMymPZnEs/uWY6vFjbpWjHhgYZ0beBPkKezZZ6HEEKIqndLBCHiNlOYDTu+h7seAO+I0u+bzbDrB/XQt5aDy1+u2QzLRsP2b9XXvadBm2fU50W5cGoTpO4HVz/wCAaPmhQ7+7E/bg3hVxST79MEs2sIrrmneWvax+wxhTHZkEIxet546Xn8fOREWiGEuBVIECIqbuVYNQhZPRmip0OTK3YezcuAJc/DoZXqa78GENLm+mXmpsOK12DvT+oKl4e/gOZPXn7f0RXqdlEfl2QXGFm55yxrz2jYtSKRrEITGblFbD52npHmFrygP80Dmk009c6HXNBHdJQARAghbiEShIiKyUmF3T+qz4uy4edn4MRf8MC7kLIfFj4Nmacu59/x3bWDkNx09bj7hK/Vw940Ouj7NTTue9VL9p/N4vvNJ1myI4m8IhOgg9MnrfJsqdEZCpbygOMutF5ALlCv+w3etBBCiMogQYiomC2zwFQENVtB7fvgr49g2zdwfB1cPA1mI3hFQLvnYcWrsHcR9JgKhn+chVJcCGunwuav1OAD1NNmu7+jroT5h2KTmZX7kpnz9wm2nbxgSa/t64qfJpvGd0Xg4+6El4sjdwW40zLEEz7/Am3GUThz6VRmCUKEEOKWIkGIKD9jAWz5r/q8/Ui1tyK8EywaDhnH1PQG0epQisEDNv8HMo6qq1RaWp/tw5opl1e/BDWHzuPgrh7WS3CB3MJiFm49zay/j3M6Ix8AvVZDj0aBPNUujFYh7qxYsYJeD0SW3iCn0SPw14fqc69w8K1ns6YQQghx8yQIEeW350fIS1eXyja4tP9GnftgxHr48z0IbAythl4OJFo8BfFvwY7/WQchF0+rp9kCRH+qTl79R/BxIbeI2X8f57uNJ8nMVw9D8nJxYFD7cJ6KCsXfQ92S/5oHJTV+9HIQUq97qc8QQghhXxKEiPJRFNg4Q33edjjorvjVcQ+AB6eVvqb5k7D633B6M6Qlgl+kmr5mCpgKSfdpwyGPXtTPM+Ltqh42l5ZdyH//Osb/Np28NN8Dwn1ceObu2jzWshbOjhXYqtS/Ifg3gtR9UL/3jdy1EEKISiRBiCifY2sg7QA4uJZ/2a17oDrEkrgctn9H5t1vsmnjWrrt+gEt8MzZaHbNUudrBHgYqOPnxvZTFyw7mTYK9iDmvrp0bxSITnsDvRgaDQyYB2mHoHbnil8vhBCiUkkQIsqnpBekxVPgXKP817UYBInLyd86l/bropih/RCtTmGZqR3GwJaEFRVz8nweKVmFpGQVAtA8pAYvdanLfZH+N3/irFe4+hBCCHHLkSBEXF9aonoOCxpoN6Ji19brToGTH84FaYzVfEdn3S5MGj0th37M8toNAcgpLOZQSjaHU7IJ9XalXW3vW/64eyGEEDdPghBxbcVFEP+2+rx+b/UQuQrYeTaHzXkd+Jf2Fwbr4wDQtXmG4EsBCICbQU/LUC9ahnrZrNpCCCFufXJwRnVTXARnd6gTTa8nMwnm9ISDywANdBxVoY86l5nPc99t5QfjFft+OLrDva9WrM5CCCHuSBKEVDd/fQRfdb58QNzVHPsT/nMPJG0FJ094cgGEtC33x+QVFfPst1tJyy7E4H8XxWGXTrjtNApcZet0IYQQMhxT/ZSc6bLlvxA1ouy9MzbOgFXjQTFDYBN4/H9lH1T3D5l5RnaeuciOUxeIP5DKvrNZ+Lg68t8hrdHrv4aTf6sbiAkhhBBIEFK9FOZA8h71+fkjcGZL6d6N1APw+zj1ebMn1f0/HJyvWmR2gZFF25P4IeEUB5Ozrd5z1Gv5z6BWhHi7AC7WB90JIYSo9iQIqU7ObgfFdPn1znmlg5BNl5biRvaGPjOuusvokdRsvtt4kp+3nSG36HKZ4T4utAj1onlIDe6L9CfUx8XWdyGEEOIOIUFIdXJqs/rTM1Q96XbvInhg6uWejtx02LVAfd7hxasGIDP/PMq7Kw5aXtf1d2Nw+zB6NwnCx81QmXcghBDiDiJBSHVy+lIQ0v4Fdd5H5ik4+NvlYZIts8BUCMEtILRdmUV8u+GEJQDp1jCAoR3CaV/HR/b1EEIIUWGyOqa6MJsvH2kf2g6aPaE+3zlP/VlcePmE3HYjy+wF+WnbGSYt3QfAS/fX5evBrelQ11cCECGEEDdEgpDqIj0RCjLBwQUCGkPzAWr6sTWQdRb2/AS5qeAeDI36lLp8xZ5zvPrTLgCGdgxnTLe7qrDyQggh7kQShFQXpzapP2u2Ap2DuvNpaAd1Ge6u+ZcnpEYNV9+/wuqDKbw0fwdmBfq3DmHigw2l90MIIcRNkyCkujh9xVBMieZPqj//mgYpe9VeklZPW95WFIX//HmUZ7/ditGk0LtpEFMebSIBiBBCCJuQIKS6OH2pJyQk6nJaw4dB7wxFl/b3aP4kOKvnt+QVFRPzww6mrjiIWYF+rWrx8ePN0WklABFCCGEbsjqmOshJg4xj6vNabS6nO3lAw4dg96VluVHPA3DyfC7/+t82DiZno9dqmPRQI56KCpUeECGEEDYlQUh1ULI0168BONewfq/tcNj7MzR6FMWnDgu3nuadX/eTXViMr5uBL59qSZtw7yqvshBCiDufBCHVQUkQEhpV+r1areHlw5wr0DPumy2sTUwDoGVoDWYMbEWgp1MVVlQIIUR1IkFIdVAShISUEYQAC/fn8vay/WQXFOOo1/J/3e7i2btry/wPIYQQlUqCkDtdcSGc3aE+LyMIWb7nHK/8tBuA5iE1+LBfU+r6u1dlDYUQQlRTEoTc6c7uBFMRuPiqe4Ncodhk5oPfEwEY3D6MiQ82RK+TBVNCCCGqhnzj3OlKluaGtiu1FfvP289wPD0Xb1dHXn2gvgQgQgghqpR869zpSjYpC2lrlVxgNPHJH4cBeKFzHdwM0ikmhBCiakkQcidTlCuCEOv5IPM2n+JsZgFBnk481S7MDpUTQghR3UkQcifLPK0eSqfVQ1AzS3JuYTFfrDkCwEtd6uHkoLNXDYUQQlRjt0QQ8sUXXxAeHo6TkxNRUVEkJCRcM//06dOJjIzE2dmZkJAQxowZQ0FBgeX9qVOn0qZNG9zd3fH396dPnz4kJiZW9m3cepK2qT8DGoGDsyV5zt/HOZ9bRLiPC4+1qmWnygkhhKju7B6ELFiwgNjYWCZNmsT27dtp1qwZPXr0IDU1tcz88+bNY+zYsUyaNIkDBw4wa9YsFixYwOuvv27J8+effzJy5Eg2bdpEXFwcRqOR7t27k5ubW1W3dWsoCUJqtrIkXcwr4j/r1C3cx3S7CweZjCqEEMJO7D4bcdq0aTz33HMMHToUgJkzZ/Lbb78xe/Zsxo4dWyr/hg0b6NixI08+qZ4AGx4ezoABA9i8ebMlz8qVK62u+eabb/D392fbtm3cc889lXg3t5gzJUFIa0vS9D8Ok11QTP1Ad6KbBtupYkIIIYSdg5CioiK2bdvGuHHjLGlarZauXbuycePGMq/p0KED33//PQkJCbRt25Zjx46xfPlyBg0adNXPyczMBMDbu+wzUAoLCyksLLS8zsrKAsBoNGI0Git8X2UpKcdW5V2XuRj9uZ1oAGNAMzAa2XD0PN9sOAHAq93rYTIVYzJVTXUqS5W3azUgbWp70qaVQ9rV9mzRphW51q5BSHp6OiaTiYCAAKv0gIAADh48WOY1Tz75JOnp6XTq1AlFUSguLmbEiBFWwzFXMpvNjB49mo4dO9K4ceMy80ydOpW33nqrVPqqVatwcXGp4F1dW1xcnE3LuxqP/FPcZ8zDqHViecJh8kxHeW+XDtDQIcBM9uEElh+ukqpUiapq1+pE2tT2pE0rh7Sr7d1Mm+bl5ZU7r92HYypq7dq1TJkyhRkzZhAVFcWRI0cYNWoU77zzDhMmTCiVf+TIkezdu5f169dftcxx48YRGxtreZ2VlUVISAjdu3fHw8PDJvU2Go3ExcXRrVs3HBwcbFLmtWh2fAcHQRfahl69HyR24W4uFiUT5u3CjOfa4XqH7AtS1e1aHUib2p60aeWQdrU9W7RpyWhCedj1m8jX1xedTkdKSopVekpKCoGBgWVeM2HCBAYNGsSzzz4LQJMmTcjNzWX48OGMHz8erfbyRMuYmBiWLVvGunXrqFXr6qtADAYDBoOhVLqDg4PNf7Ero8wyJe8EQFurNcv2p/Hr7mR0Wg3Tn2hODTfna197G6qydq1GpE1tT9q0cki72t7NtGlFrrPr0ghHR0datWpFfHy8Jc1sNhMfH0/79u3LvCYvL88q0ADQ6dR9LhRFsfyMiYlh8eLFrF69moiIiEq6g1tY0nYALng15Y3FewAYeV9dWoR62bNWQgghhIXd++RjY2MZMmQIrVu3pm3btkyfPp3c3FzLapnBgwdTs2ZNpk6dCkB0dDTTpk2jRYsWluGYCRMmEB0dbQlGRo4cybx58/jll19wd3cnOTkZAE9PT5yd77xegFIKcyB1PwCTd7mQVVBMs1qevHh/XTtXTAghhLjM7kFI//79SUtLY+LEiSQnJ9O8eXNWrlxpmax66tQpq56PN954A41GwxtvvEFSUhJ+fn5ER0czefJkS54vv/wSgM6dO1t91pw5c3j66acr/Z7s7twuUMyY3YJYfMQMwAf9msmeIEIIIW4pdg9CQJ27ERMTU+Z7a9eutXqt1+uZNGkSkyZNump5JcMy1VbSVgBS3BthSle4K8CNuwLc7VwpIYQQwpr8aXwnurRT6tbi2gDcV9/fnrURQgghyiRByJ3o0qTUpelBANwfKUGIEEKIW48EIXea7BTIPI2Cho35IXg46WkVJitihBBC3HokCLnTXBqKSXeOIAcX7o30Ry8TUoUQQtyC5NvpTnMpCNluUueD3F/fz561EUIIIa5KgpA7zaWVMetyQ9Fo4N67ZD6IEEKIW5MEIXcSsxmSdgCw01yXFiE18HZ1tHOlhBBCiLJJEHInOboaCjMp1BhIVGrRpUHA9a8RQggh7ESCkDuFqRhWjQfgB9P9FKPnPlmaK4QQ4hYmQcidYvs3kHaQIkcvphU9QpCnEw2CZJdUIYQQt64KByHh4eG8/fbbnDp1qjLqI25E/kVYrZ6ds8p/KFm40TnSH41GY996CSGEENdQ4SBk9OjRLFq0iNq1a9OtWzfmz59PYWFhZdRNlNe6DyA/A8U3kvfTOgBwv2zVLoQQ4hZ3Q0HIzp07SUhIoEGDBrz44osEBQURExPD9u3bK6OO4lrOH4XN/wHgWMtxnMoswlGvpWNdHztXTAghhLi2G54T0rJlSz799FPOnj3LpEmT+O9//0ubNm1o3rw5s2fPlpNsq0rcRDAboW5XvjgdAcCDTYJwcbwlDkgWQgghruqGgxCj0ciPP/7IQw89xP/93//RunVr/vvf/9K3b19ef/11Bg4caMt6irKc+BsOLgONjgudJrFs9zkABncIt2+9hBBCiHKo8J/L27dvZ86cOfzwww9otVoGDx7Mxx9/TP369S15HnnkEdq0aWPTiooyrHtf/dlyMHOPOVNkMtMspAbNQ2rYtVpCCCFEeVQ4CGnTpg3dunXjyy+/pE+fPjg4OJTKExERwRNPPGGTCoqrSNoOx9aCRoexw2i+/89RAJ7uEGbfegkhhBDlVOEg5NixY4SFXfuLztXVlTlz5txwpUQ5rJ+m/mzSj7izBpKzCvB1c6RXkyD71ksIIYQopwrPCUlNTWXz5s2l0jdv3szWrVttUilxHWmH4MAy9Xmn0Xyz4QQAA9qGYtDr7FcvIYQQogIqHISMHDmS06dPl0pPSkpi5MiRNqmUuI6/pwMKRPbmgKkmCccz0Gk1DIySoRghhBC3jwoHIfv376dly5al0lu0aMH+/fttUilxDRdPw+4F6vO7Y/n2Ui/IA40CCfR0sl+9hBBCiAqqcBBiMBhISUkplX7u3Dn0etmbotJt+AzMxRBxDxe9m7JkZxIAQ2RZrhBCiNtMhYOQ7t27M27cODIzMy1pFy9e5PXXX6dbt242rZz4h9x02P6d+rxTLEt3naXAaKZBkAdtwr3sWzchhBCigircdfHhhx9yzz33EBYWRosWLQDYuXMnAQEB/O9//7N5BcUVNv8HivMhuAXU7kzc2gQA+jQPlsPqhBBC3HYqHITUrFmT3bt3M3fuXHbt2oWzszNDhw5lwIABZe4ZImzEbIZdP6jPO7xIdmExm46dB6BrwwA7VkwIIYS4MTc0icPV1ZXhw4fbui7iWs5sgczT4OgGkb1YdyAdo0mhtq8rdfzc7F07IYQQosJueCbp/v37OXXqFEVFRVbpDz300E1XSpRh78/qz/q9wcGZ+AOJAHRp4G/HSgkhhBA37oZ2TH3kkUfYs2cPGo3GclpuyZwEk8lk2xoKMJtg/xL1eeO+FJvMrE5MBaBrAxmKEUIIcXuq8OqYUaNGERERQWpqKi4uLuzbt49169bRunVr1q5dWwlVFJz8G3JSwKkG1L6P7acucjHPiKezA63CZFWMEEKI21OFe0I2btzI6tWr8fX1RavVotVq6dSpE1OnTuWll15ix44dlVHP6q1kKKbhQ6B35I8D6j4t99f3R6+rcBwphBBC3BIq/A1mMplwd3cHwNfXl7NnzwIQFhZGYmKibWtXnRRmw7IxsO0b63STEfb/oj5v3BfAEoTIfBAhhBC3swr3hDRu3Jhdu3YRERFBVFQU77//Po6Ojnz11VfUrl27Mup451MU+HXU5R4PvTM0668+P7YW8i+Aqz+E383RtByOpeXioNNwz11+dquyEEIIcbMqHIS88cYb5ObmAvD222/z4IMPcvfdd+Pj48OCBQtsXsFqYeusywEIwNIXwbcu1Gx1Ob1RH9DqiL/UC9Kutg8eTrIvixBCiNtXhYOQHj16WJ7XrVuXgwcPkpGRgZeXl+zaeSPO7oCV49Tn3d6Gkxvh0AqYPxCGrYQDy9T3Gj0KwB8H1FUxXerLUIwQQojbW4XmhBiNRvR6PXv37rVK9/b2vqkA5IsvviA8PBwnJyeioqJISEi4Zv7p06cTGRmJs7MzISEhjBkzhoKCgpsq0y7yL8CPQ8BUBJG9ocNL8OhX4Fcfss/Bf7tCUTZ41ISQKC7kFrH1RAYAXWRprhBCiNtchYIQBwcHQkNDbboXyIIFC4iNjWXSpEls376dZs2a0aNHD1JTU8vMP2/ePMaOHcukSZM4cOAAs2bNYsGCBbz++us3XKZdKAosGQkXT0KNMOgzAzQacPKAJ+apy3Fz09S8jR4BrZa1h1IxK1A/0J0Qbxe7Vl8IIYS4WRVeHTN+/Hhef/11MjIybFKBadOm8dxzzzF06FAaNmzIzJkzcXFxYfbs2WXm37BhAx07duTJJ58kPDyc7t27M2DAAKuejoqWaRd7f4bE30DnCI9/C841Lr/nUwf6zQHNpX+eJo8BsGqfOh9ENigTQghxJ6jwnJDPP/+cI0eOEBwcTFhYGK6urlbvb9++vdxlFRUVsW3bNsaNG2dJ02q1dO3alY0bN5Z5TYcOHfj+++9JSEigbdu2HDt2jOXLlzNo0KAbLrOwsJDCwkLL66ysLEAdfjIajeW+n2spKafkp/b4X+gAU+tnMPs1hn9+TujdaJ5YAHnpKH6Nyc7OJ/7gpV1S6/varF63u3+2q7h50qa2J21aOaRdbc8WbVqRayschPTp06eil1xVeno6JpOJgADrv+wDAgI4ePBgmdc8+eSTpKen06lTJxRFobi4mBEjRliGY26kzKlTp/LWW2+VSl+1ahUuLrYd9oiLiwOgw+HN+AE7k82cWb78Gle4wqnlJKRqKCrWEeCscGLHek7utGm1bnsl7SpsR9rU9qRNK4e0q+3dTJvm5eWVO2+Fg5BJkyZV9BKbWrt2LVOmTGHGjBlERUVx5MgRRo0axTvvvMOECRNuqMxx48YRGxtreZ2VlUVISAjdu3fHw8PDJvU2Go3ExcXRrVs3HBwc0H/yCgDN7utL05otr3v9wm+3AecZ0KEevTvLfiwl/tmu4uZJm9qetGnlkHa1PVu0acloQnnc8Cm6tuDr64tOpyMlJcUqPSUlhcDAwDKvmTBhAoMGDeLZZ58FoEmTJuTm5jJ8+HDGjx9/Q2UaDAYMBkOpdAcHB5v/Yjs4OOBgylfPggH0gfXhOp+Rml3AhqPnAXikZS35j60MlfFvVd1Jm9qetGnlkHa1vZtp04pcV+GJqVqtFp1Od9VHRTg6OtKqVSvi4+MtaWazmfj4eNq3b1/mNXl5eWi11tUu+VxFUW6ozCp3/rD60y0QnDyvm/233ecwK9A8pAZhPq7XzS+EEELcDircE7J48WKr10ajkR07dvDtt9+WOa/iemJjYxkyZAitW7embdu2TJ8+ndzcXIYOHQrA4MGDqVmzJlOnTgUgOjqaadOm0aJFC8twzIQJE4iOjrYEI9cr0+7SLwUhvvXKlf2Xner5PA83D66sGgkhhBBVrsJByMMPP1wq7bHHHqNRo0YsWLCAZ555pkLl9e/fn7S0NCZOnEhycjLNmzdn5cqVlomlp06dsur5eOONN9BoNLzxxhskJSXh5+dHdHQ0kydPLneZdleBIOTk+Vx2nr6IVgO9mwZVcsWEEEKIqmOzOSHt2rVj+PDhN3RtTEwMMTExZb63du1aq9d6vZ5JkyZdd4Lstcq0u/RD6k+f6wchSy/1gnSs64u/u1Nl1koIIYSoUhWeE1KW/Px8Pv30U2rWrGmL4u5854+oP33vumY2RVFYsjMJgIebS9sKIYS4s1S4J+SfB9UpikJ2djYuLi58//33Nq3cHclsgvNH1ee+da+Zdf+5LI6m5eKo19Kj0S0ylCSEEELYSIWDkI8//tgqCNFqtfj5+REVFYWXl5dNK3dHyjwNpkLQO4FnyDWzlgzFdG3gj7uTLD8TQghxZ6lwEPL0009XQjWqD03J8lzvOqC9+pJmRVFYtvscAA81k6EYIYQQd54KzwmZM2cOCxcuLJW+cOFCvv32W5tU6k5mCUKuszLmzIV8ki7m46DTcO9dflVQMyGEEKJqVTgImTp1Kr6+vqXS/f39mTJlik0qdUezTEq9dhCy5YR6SnHjmp44O1ZsEzghhBDidlDhIOTUqVNERESUSg8LC+PUqVM2qdSd7HJPyLVXxmw9eQGA1mEyz0YIIcSdqcJBiL+/P7t37y6VvmvXLnx8fGxSqTuZxrIy5to9IVsv9YS0Dveu7CoJIYQQdlHhIGTAgAG89NJLrFmzBpPJhMlkYvXq1YwaNYonnniiMup4x9AX56LJTVVf+Fx9eW5mnpFDKTmA9IQIIYS4c1V4dcw777zDiRMn6NKlC3q9ernZbGbw4MEyJ+Q63AuTLz0JBoP7VfNtO6X2gtT2dcXHrfTpvkIIIcSdoMJBiKOjIwsWLODf//43O3fuxNnZmSZNmhAWFlYZ9bujuBWo+35cb5OyLScuzQcJl14QIYQQd64bPjumXr161KtXvlNghcqtUN3343qTUreVBCFhMh9ECCHEnavCc0L69u3Le++9Vyr9/fffp1+/fjap1J3KreBSEHKNg+sKi03sPHMRkJ4QIYQQd7YKByHr1q2jV69epdJ79uzJunXrbFKpO5W7pSfk6kHI3qQsiorN+Lg6EuHrWkU1E0IIIapehYOQnJwcHB0dS6U7ODiQlZVlk0rdkczFuBamqM+vEYSULM1tFWZ9UKAQQghxp6lwENKkSRMWLFhQKn3+/Pk0bNjQJpW6I108iVYxoeidwaPWVbOVTEptI/uDCCGEuMNVeGLqhAkTePTRRzl69Cj3338/APHx8cybN4+ffvrJ5hW8U2hKtmv3rgPasmM/RVHYdvJST4jMBxFCCHGHq3AQEh0dzZIlS5gyZQo//fQTzs7ONGvWjNWrV+PtLX+9X03Jdu2Kb12uNshyNC2XC3lGDHotjYM9q65yQgghhB3c0BLd3r1707t3bwCysrL44YcfePnll9m2bRsmk8mmFbxTaNIvBSHXWBlT0gvSPKQGjvoKj5QJIYQQt5Ub/qZbt24dQ4YMITg4mI8++oj777+fTZs22bJud5YM9cwY5RrbtcsmZUIIIaqTCvWEJCcn88033zBr1iyysrJ4/PHHKSwsZMmSJTIp9TqURo9yMteR4MCmV80jh9YJIYSoTsrdExIdHU1kZCS7d+9m+vTpnD17ls8++6wy63ZHMbcaxs6wZ6+6UVladiEnzueh0UDLUOkJEUIIcecrd0/IihUreOmll3j++edlu/ZKsCfpIgB1/dzwdHawb2WEEEKIKlDunpD169eTnZ1Nq1atiIqK4vPPPyc9Pb0y61at7D+rbvTWKNjDzjURQgghqka5g5B27drx9ddfc+7cOf71r38xf/58goODMZvNxMXFkZ2dXZn1vOPtP6cGIQ0lCBFCCFFNVHh1jKurK8OGDWP9+vXs2bOH//u//+Pdd9/F39+fhx56qDLqWC2U9IQ0DJL9QYQQQlQPN7UZRWRkJO+//z5nzpzhhx9+sFWdqp2cwmJOZuQB0CDI3c61EUIIIaqGTXbE0ul09OnTh6VLl9qiuGonMTkLRYEADwM+bgZ7V0cIIYSoErIt5y3g8lCMzAcRQghRfUgQcgvYf06d1CuTUoUQQlQnEoTcAkpWxjSQnhAhhBDViAQhdlZsMnPwnAzHCCGEqH4kCLGzE+dzKSw24+KoI8zH1d7VEUIIIarMLRGEfPHFF4SHh+Pk5ERUVBQJCQlXzdu5c2c0Gk2pR+/evS15cnJyiImJoVatWjg7O9OwYUNmzpxZFbdSYSXzQSID3dFpNXaujRBCCFF17B6ELFiwgNjYWCZNmsT27dtp1qwZPXr0IDU1tcz8ixYt4ty5c5bH3r170el09OvXz5InNjaWlStX8v3333PgwAFGjx5NTEzMLbmEWFbGCCGEqK7sHoRMmzaN5557jqFDh1p6LFxcXJg9e3aZ+b29vQkMDLQ84uLicHFxsQpCNmzYwJAhQ+jcuTPh4eEMHz6cZs2aXbOHxV5ku3YhhBDVVblP0a0MRUVFbNu2jXHjxlnStFotXbt2ZePGjeUqY9asWTzxxBO4ul6eT9GhQweWLl3KsGHDCA4OZu3atRw6dIiPP/64zDIKCwspLCy0vM7KUgMDo9GI0Wi8kVsrpaScf5a3/2wmAHf5udjss6qTq7WruHHSprYnbVo5pF1tzxZtWpFr7RqEpKenYzKZCAgIsEoPCAjg4MGD170+ISGBvXv3MmvWLKv0zz77jOHDh1OrVi30ej1arZavv/6ae+65p8xypk6dyltvvVUqfdWqVbi4uFTgjq4vLi7O8jyrCNJz9GhQOL5zA2f32PSjqpUr21XYhrSp7UmbVg5pV9u7mTbNy8srd167BiE3a9asWTRp0oS2bdtapX/22Wds2rSJpUuXEhYWxrp16xg5ciTBwcF07dq1VDnjxo0jNjbW8jorK4uQkBC6d++Oh4dthkmMRiNxcXF069YNBwcHAP46nA7bthPh68oj0Z1s8jnVTVntKm6OtKntSZtWDmlX27NFm5aMJpSHXYMQX19fdDodKSkpVukpKSkEBgZe89rc3Fzmz5/P22+/bZWen5/P66+/zuLFiy0rZpo2bcrOnTv58MMPywxCDAYDBkPpM1scHBxs/ot9ZZmJqWq02DDYU/4DukmV8W9V3Umb2p60aeWQdrW9m2nTilxn14mpjo6OtGrVivj4eEua2WwmPj6e9u3bX/PahQsXUlhYyFNPPWWVXjKPQ6u1vjWdTofZbLZd5W3ggOyUKoQQohqz+3BMbGwsQ4YMoXXr1rRt25bp06eTm5vL0KFDARg8eDA1a9Zk6tSpVtfNmjWLPn364OPjY5Xu4eHBvffeyyuvvIKzszNhYWH8+eeffPfdd0ybNq3K7qs8ZGWMEEKI6szuQUj//v1JS0tj4sSJJCcn07x5c1auXGmZrHrq1KlSvRqJiYmsX7+eVatWlVnm/PnzGTduHAMHDiQjI4OwsDAmT57MiBEjKv1+yiu/yMSxtBwAGklPiBBCiGrI7kEIQExMDDExMWW+t3bt2lJpkZGRKIpy1fICAwOZM2eOrapXKRJTsjEr4OPqiJ976fkoQgghxJ3O7puVVVcHrhiK0Whku3YhhBDVjwQhdnLuYj4AYT623YdECCGEuF1IEGInuUUmAFwNt8SImBBCCFHlJAixk7yiYgDcHCUIEUIIUT1JEGInOYVqT4iL9IQIIYSopiQIsZO8QrUnxNVRZ+eaCCGEEPYhQYid5F4ajpE5IUIIIaorCULsJLewZGKq9IQIIYSoniQIsZOSnhAXmZgqhBCimpIgxE7yLvWEuMlwjBBCiGpKghA7yS0s6QmR4RghhBDVkwQhdqAoikxMFUIIUe1JEGIHhcVmzJfO35MgRAghRHUlQYgd5FwaigFwdpDhGCGEENWTBCF2UDIp1dlBh04rJ+gKIYSoniQIsQOZDyKEEEJIEGIXJStjZKMyIYQQ1ZkEIXaQW3Tp8DrZqEwIIUQ1JkGIHZQcXucmPSFCCCGqMQlC7CCnULZsF0IIISQIsYO8Ijm8TgghhJAgxA4sq2OkJ0QIIUQ1JkGIHVxeHSNBiBBCiOpLghA7yC0sWR0jwzFCCCGqLwlC7CBPNisTQgghJAixh5KeEFfpCRFCCFGNSRBiByUTU12kJ0QIIUQ1JkGIHZQcYOcmQYgQQohqTIIQO7D0hMhwjBBCiGpMghA7kCW6QgghhAQhdlFygJ1sViaEEKI6kyDEDvIsPSEyHCOEEKL6kiCkipnNiqUnRA6wE0IIUZ1JEFLF8o0my3NZHSOEEKI6uyWCkC+++ILw8HCcnJyIiooiISHhqnk7d+6MRqMp9ejdu7dVvgMHDvDQQw/h6emJq6srbdq04dSpU5V9K9dVcoKuRgNODrdE8wshhBB2YfdvwQULFhAbG8ukSZPYvn07zZo1o0ePHqSmppaZf9GiRZw7d87y2Lt3Lzqdjn79+lnyHD16lE6dOlG/fn3Wrl3L7t27mTBhAk5OTlV1W1d15Qm6Go3GzrURQggh7Mfu4wHTpk3jueeeY+jQoQDMnDmT3377jdmzZzN27NhS+b29va1ez58/HxcXF6sgZPz48fTq1Yv333/fklanTp2r1qGwsJDCwkLL66ysLACMRiNGo/HGbuwfSsrJzFU/x9VRZ7Oyq7OSNpS2tB1pU9uTNq0c0q62Z4s2rci1GkVRlBv+pJtUVFSEi4sLP/30E3369LGkDxkyhIsXL/LLL79ct4wmTZrQvn17vvrqKwDMZjOenp68+uqrrF+/nh07dhAREcG4ceOsPuNKb775Jm+99Vap9Hnz5uHi4nJD93Y1R7Pg0316/J0UxrcwXf8CIYQQ4jaSl5fHk08+SWZmJh4eHtfMa9eekPT0dEwmEwEBAVbpAQEBHDx48LrXJyQksHfvXmbNmmVJS01NJScnh3fffZd///vfvPfee6xcuZJHH32UNWvWcO+995YqZ9y4ccTGxlpeZ2VlERISQvfu3a/bgOVlNBqJi4ujQdOWsG83ft4e9OrV3iZlV2cl7dqtWzccHBzsXZ07grSp7UmbVg5pV9uzRZuWjCaUh92HY27GrFmzaNKkCW3btrWkmc1mAB5++GHGjBkDQPPmzdmwYQMzZ84sMwgxGAwYDIZS6Q4ODjb/xb40LxU3g+3Lrs4q49+qupM2tT1p08oh7Wp7N9OmFbnOrhNTfX190el0pKSkWKWnpKQQGBh4zWtzc3OZP38+zzzzTKky9Xo9DRs2tEpv0KDBLbE6xrJbqizPFUIIUc3ZNQhxdHSkVatWxMfHW9LMZjPx8fG0b3/toYqFCxdSWFjIU089VarMNm3akJiYaJV+6NAhwsLCbFf5GySH1wkhhBAqu/85Hhsby5AhQ2jdujVt27Zl+vTp5ObmWlbLDB48mJo1azJ16lSr62bNmkWfPn3w8fEpVeYrr7xC//79ueeee7jvvvtYuXIlv/76K2vXrq2KW7qmvEK1J0Q2KhNCCFHd2f2bsH///qSlpTFx4kSSk5Np3rw5K1eutExWPXXqFFqtdYdNYmIi69evZ9WqVWWW+cgjjzBz5kymTp3KSy+9RGRkJD///DOdOnWq9Pu5njzZsl0IIYQAboEgBCAmJoaYmJgy3yur9yIyMpLrrSweNmwYw4YNs0X1bMqyWZkcXieEEKKas/uOqdWNTEwVQgghVBKEVLG8wpJt26UnRAghRPUmQUgVy5U5IUIIIQQgQUiVy5PhGCGEEAKQIKTKWYZjZGKqEEKIak6CkCqWI8MxQgghBCBBSJXLu7REVzYrE0IIUd1JEFLFLm9WJsMxQgghqjcJQqqQSYECo3rKr0xMFUIIUd1JEFKFLnWCADIxVQghhJAgpApdOrsOvVaDo06aXgghRPUm34RVqFAdicHFUYdGo7FvZYQQQgg7kyCkCpX0hMjKGCGEEEKCkCpVaFJ7P1wkCBFCCCEkCKlKJT0hcnidEEIIIUFIlSqZEyLLc4UQQggJQqpUSU+IbNkuhBBCSBBSpSzDMbJHiBBCCCFBSFW6HIRIT4gQQgghQUgVKjSrq2NkYqoQQgghQUiVkjkhQgghxGUShFQh2axMCCGEuEyCkCpk6QmRialCCCGEBCFVybJPiAzHCCGEEBKEVKWSbdtldYwQQgghQUiVkm3bhRBCiMskCKlCl+eESE+IEEIIIUFIFSqZE+ImE1OFEEIICUKqkuwTIoQQQlwmQUgVKSo2Y1JKdkyVIEQIIYSQIKSK5BWZLM9lnxAhhBBCgpAqk1dUDICjXouDTppdCCGEkG/DKpJ7aUKILM8VQgghVLdEEPLFF18QHh6Ok5MTUVFRJCQkXDVv586d0Wg0pR69e/cuM/+IESPQaDRMnz69kmpfPrmXekIkCBFCCCFUdg9CFixYQGxsLJMmTWL79u00a9aMHj16kJqaWmb+RYsWce7cOctj79696HQ6+vXrVyrv4sWL2bRpE8HBwZV9G9dVMidEVsYIIYQQKrsHIdOmTeO5555j6NChNGzYkJkzZ+Li4sLs2bPLzO/t7U1gYKDlERcXh4uLS6kgJCkpiRdffJG5c+fi4OBQFbdyTSXDMTIpVQghhFDZ9c/yoqIitm3bxrhx4yxpWq2Wrl27snHjxnKVMWvWLJ544glcXV0taWazmUGDBvHKK6/QqFGj65ZRWFhIYWGh5XVWVhYARqMRo9FY3tu5pqx8tXwXB63NyhRY2lLa1HakTW1P2rRySLvani3atCLX2jUISU9Px2QyERAQYJUeEBDAwYMHr3t9QkICe/fuZdasWVbp7733Hnq9npdeeqlc9Zg6dSpvvfVWqfRVq1bh4uJSrjKuZ1uyBtCRc/E8y5cvt0mZ4rK4uDh7V+GOI21qe9KmlUPa1fZupk3z8vLKnfe2nqAwa9YsmjRpQtu2bS1p27Zt45NPPmH79u1oNJpylTNu3DhiY2Mtr7OysggJCaF79+54eHjYpK6n/jwKx48SXiuIXr2a2aRMoUbccXFxdOvW7ZYYdrsTSJvanrRp5ZB2tT1btGnJaEJ52DUI8fX1RafTkZKSYpWekpJCYGDgNa/Nzc1l/vz5vP3221bpf/31F6mpqYSGhlrSTCYT//d//8f06dM5ceJEqbIMBgMGg6FUuoODg81+sQuLFQDcnRzlP5ZKYMt/K6GSNrU9adPKIe1qezfTphW5zq4TUx0dHWnVqhXx8fGWNLPZTHx8PO3bt7/mtQsXLqSwsJCnnnrKKn3QoEHs3r2bnTt3Wh7BwcG88sor/P7775VyH+VxeXWMTEwVQggh4BYYjomNjWXIkCG0bt2atm3bMn36dHJzcxk6dCgAgwcPpmbNmkydOtXqulmzZtGnTx98fHys0n18fEqlOTg4EBgYSGRkZOXezDWU7BMiQYgQQgihsnsQ0r9/f9LS0pg4cSLJyck0b96clStXWiarnjp1Cq3WusMmMTGR9evXs2rVKntU+YZYdkw12L3JhRBCiFvCLfGNGBMTQ0xMTJnvrV27tlRaZGQkiqKUu/yy5oFUtZLhGNkxVQghhFDZfbOy6kKGY4QQQghrEoRUkbv83Qh3U/D3KL0KRwghhKiObonhmOpg4oMNWK49Tttwb3tXRQghhLglSE+IEEIIIexCghAhhBBC2IUEIUIIIYSwCwlChBBCCGEXEoQIIYQQwi4kCBFCCCGEXUgQIoQQQgi7kCBECCGEEHYhQYgQQggh7EKCECGEEELYhQQhQgghhLALOTumDIqiAJCVlWWzMo1GI3l5eWRlZeHg4GCzcqs7aVfbkza1PWnTyiHtanu2aNOS786S79JrkSCkDNnZ2QCEhITYuSZCCCHE7Sk7OxtPT89r5tEo5QlVqhmz2czZs2dxd3dHo9HYpMysrCxCQkI4ffo0Hh4eNilTSLtWBmlT25M2rRzSrrZnizZVFIXs7GyCg4PRaq8960N6Qsqg1WqpVatWpZTt4eEh/7FUAmlX25M2tT1p08oh7Wp7N9um1+sBKSETU4UQQghhFxKECCGEEMIuJAipIgaDgUmTJmEwGOxdlTuKtKvtSZvanrRp5ZB2tb2qblOZmCqEEEIIu5CeECGEEELYhQQhQgghhLALCUKEEEIIYRcShAghhBDCLiQIqSJffPEF4eHhODk5ERUVRUJCgr2rdNuYOnUqbdq0wd3dHX9/f/r06UNiYqJVnoKCAkaOHImPjw9ubm707duXlJQUO9X49vPuu++i0WgYPXq0JU3a9MYkJSXx1FNP4ePjg7OzM02aNGHr1q2W9xVFYeLEiQQFBeHs7EzXrl05fPiwHWt8azOZTEyYMIGIiAicnZ2pU6cO77zzjtW5JNKm17du3Tqio6MJDg5Go9GwZMkSq/fL04YZGRkMHDgQDw8PatSowTPPPENOTs7NVUwRlW7+/PmKo6OjMnv2bGXfvn3Kc889p9SoUUNJSUmxd9VuCz169FDmzJmj7N27V9m5c6fSq1cvJTQ0VMnJybHkGTFihBISEqLEx8crW7duVdq1a6d06NDBjrW+fSQkJCjh4eFK06ZNlVGjRlnSpU0rLiMjQwkLC1OefvppZfPmzcqxY8eU33//XTly5Iglz7vvvqt4enoqS5YsUXbt2qU89NBDSkREhJKfn2/Hmt+6Jk+erPj4+CjLli1Tjh8/rixcuFBxc3NTPvnkE0seadPrW758uTJ+/Hhl0aJFCqAsXrzY6v3ytOEDDzygNGvWTNm0aZPy119/KXXr1lUGDBhwU/WSIKQKtG3bVhk5cqTltclkUoKDg5WpU6fasVa3r9TUVAVQ/vzzT0VRFOXixYuKg4ODsnDhQkueAwcOKICyceNGe1XztpCdna3Uq1dPiYuLU+69915LECJtemNee+01pVOnTld932w2K4GBgcoHH3xgSbt48aJiMBiUH374oSqqeNvp3bu3MmzYMKu0Rx99VBk4cKCiKNKmN+KfQUh52nD//v0KoGzZssWSZ8WKFYpGo1GSkpJuuC4yHFPJioqK2LZtG127drWkabVaunbtysaNG+1Ys9tXZmYmAN7e3gBs27YNo9Fo1cb169cnNDRU2vg6Ro4cSe/eva3aDqRNb9TSpUtp3bo1/fr1w9/fnxYtWvD1119b3j9+/DjJyclW7erp6UlUVJS061V06NCB+Ph4Dh06BMCuXbtYv349PXv2BKRNbaE8bbhx40Zq1KhB69atLXm6du2KVqtl8+bNN/zZcoBdJUtPT8dkMhEQEGCVHhAQwMGDB+1Uq9uX2Wxm9OjRdOzYkcaNGwOQnJyMo6MjNWrUsMobEBBAcnKyHWp5e5g/fz7bt29ny5Ytpd6TNr0xx44d48svvyQ2NpbXX3+dLVu28NJLL+Ho6MiQIUMsbVfW/w+kXcs2duxYsrKyqF+/PjqdDpPJxOTJkxk4cCCAtKkNlKcNk5OT8ff3t3pfr9fj7e19U+0sQYi4rYwcOZK9e/eyfv16e1fltnb69GlGjRpFXFwcTk5O9q7OHcNsNtO6dWumTJkCQIsWLdi7dy8zZ85kyJAhdq7d7enHH39k7ty5zJs3j0aNGrFz505Gjx5NcHCwtOkdQIZjKpmvry86na7UqoKUlBQCAwPtVKvbU0xMDMuWLWPNmjXUqlXLkh4YGEhRUREXL160yi9tfHXbtm0jNTWVli1botfr0ev1/Pnnn3z66afo9XoCAgKkTW9AUFAQDRs2tEpr0KABp06dArC0nfz/oPxeeeUVxo4dyxNPPEGTJk0YNGgQY8aMYerUqYC0qS2Upw0DAwNJTU21er+4uJiMjIybamcJQiqZo6MjrVq1Ij4+3pJmNpuJj4+nffv2dqzZ7UNRFGJiYli8eDGrV68mIiLC6v1WrVrh4OBg1caJiYmcOnVK2vgqunTpwp49e9i5c6fl0bp1awYOHGh5Lm1acR07diy1fPzQoUOEhYUBEBERQWBgoFW7ZmVlsXnzZmnXq8jLy0Ortf6q0ul0mM1mQNrUFsrThu3bt+fixYts27bNkmf16tWYzWaioqJu/MNveEqrKLf58+crBoNB+eabb5T9+/crw4cPV2rUqKEkJyfbu2q3heeff17x9PRU1q5dq5w7d87yyMvLs+QZMWKEEhoaqqxevVrZunWr0r59e6V9+/Z2rPXt58rVMYoibXojEhISFL1er0yePFk5fPiwMnfuXMXFxUX5/vvvLXneffddpUaNGsovv/yi7N69W3n44YdlOek1DBkyRKlZs6Zlie6iRYsUX19f5dVXX7XkkTa9vuzsbGXHjh3Kjh07FECZNm2asmPHDuXkyZOKopSvDR944AGlRYsWyubNm5X169cr9erVkyW6t4vPPvtMCQ0NVRwdHZW2bdsqmzZtsneVbhtAmY85c+ZY8uTn5ysvvPCC4uXlpbi4uCiPPPKIcu7cOftV+jb0zyBE2vTG/Prrr0rjxo0Vg8Gg1K9fX/nqq6+s3jebzcqECROUgIAAxWAwKF26dFESExPtVNtbX1ZWljJq1CglNDRUcXJyUmrXrq2MHz9eKSwstOSRNr2+NWvWlPn/0SFDhiiKUr42PH/+vDJgwADFzc1N8fDwUIYOHapkZ2ffVL00inLFtnNCCCGEEFVE5oQIIYQQwi4kCBFCCCGEXUgQIoQQQgi7kCBECCGEEHYhQYgQQggh7EKCECGEEELYhQQhQgghhLALCUKEEEIIYRcShAghqg2NRsOSJUvsXQ0hxCUShAghqsTTTz+NRqMp9XjggQfsXTUhhJ3o7V0BIUT18cADDzBnzhyrNIPBYKfaCCHsTXpChBBVxmAwEBgYaPXw8vIC1KGSL7/8kp49e+Ls7Ezt2rX56aefrK7fs2cP999/P87Ozvj4+DB8+HBycnKs8syePZtGjRphMBgICgoiJibG6v309HQeeeQRXFxcqFevHkuXLq3cmxZCXJUEIUKIW8aECRPo27cvu3btYuDAgTzxxBMcOHAAgNzcXHr06IGXlxdbtmxh4cKF/PHHH1ZBxpdffsnIkSMZPnw4e/bsYenSpdStW9fqM9566y0ef/xxdu/eTa9evRg4cCAZGRlVep9CiEtu6gxeIYQopyFDhig6nU5xdXW1ekyePFlRFEUBlBEjRlhdExUVpTz//POKoijKV199pXh5eSk5OTmW93/77TdFq9UqycnJiqIoSnBwsDJ+/Pir1gFQ3njjDcvrnJwcBVBWrFhhs/sUQpSfzAkRQlSZ++67jy+//NIqzdvb2/K8ffv2Vu+1b9+enTt3AnDgwAGaNWuGq6ur5f2OHTtiNptJTExEo9Fw9uxZunTpcs06NG3a1PLc1dUVDw8PUlNTb/SWhBA3QYIQIUSVcXV1LTU8YivOzs7lyufg4GD1WqPRYDabK6NKQojrkDkhQohbxqZNm0q9btCgAQANGjRg165d5ObmWt7/+++/0Wq1REZG4u7uTnh4OPHx8VVaZyHEjZOeECFElSksLCQ5OdkqTa/X4+vrC8DChQtp3bo1nTp1Yu7cuSQkJDBr1iwABg4cyKRJkxgyZAhvvvkmaWlpvPjiiwwaNIiAgAAA3nzzTUaMGIG/vz89e/YkOzubv//+mxdffLFqb1QIUS4ShAghqszKlSsJCgqySouMjOTgwYOAunJl/vz5vPDCCwQFBfHDDz/QsGFDAFxcXPj9998ZNWoUbdq0wcXFhb59+zJt2jRLWUOGDKGgoICPP/6Yl19+GV9fXx577LGqu0EhRIVoFEVR7F0JIYTQaDQsXryYPn362LsqQogqInNChBBCCGEXEoQIIYQQwi5kTogQ4pYgI8NCVD/SEyKEEEIIu5AgRAghhBB2IUGIEEIIIexCghAhhBBC2IUEIUIIIYSwCwlChBBCCGEXEoQIIYQQwi4kCBFCCCGEXfw/ysTsQ33PBFQAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"multiclass_model.h5\")\n",
        "\n",
        "import os\n",
        "size_mb = os.path.getsize(\"multiclass_model.h5\") / (1024*1024)\n",
        "print(f\"Model size: {size_mb:.2f} MB\")\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"multiclass_model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "ciOeIaFSwZ1T",
        "outputId": "97691be5-36a4-47b7-da8a-99befe7dc0a5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model size: 3.42 MB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0637d390-6e4e-420d-a734-38ed835fd310\", \"multiclass_model.h5\", 3590080)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Save the weights of the current good model................\n",
        "model.save_weights(\"model1_best.weights.h5\")\n",
        "print(\"Model 1 weights saved.\")\n",
        "\n",
        "# 2. Identify where to cut Model 1\n",
        "# We want everything EXCEPT the last layer (the softmax output)\n",
        "# In your residual function, the last layer is 'dense_X' (softmax),\n",
        "# and the one before it is 'add_X' (the last residual block).\n",
        "\n",
        "# Let's inspect the last few layers to be sure\n",
        "for i, layer in enumerate(model.layers[-5:]):\n",
        "    print(f\"Layer -{5-i}: {layer.name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFR0OA2_jTi0",
        "outputId": "7ddea8ca-a741-465e-d21d-3e00f968b372"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 1 weights saved.\n",
            "Layer -5: dropout_2\n",
            "Layer -4: dense_4\n",
            "Layer -3: batch_normalization_4\n",
            "Layer -2: add_1\n",
            "Layer -1: dense_5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "# y_pred_probs = model.predict(X_test_num)\n",
        "# y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# print('\\nClassification report (Keras multiclass):')\n",
        "# print(classification_report(y_test_m, y_pred_classes, digits=4))\n",
        "# print('\\nConfusion matrix (Keras multiclass):')\n",
        "# print(confusion_matrix(y_test_m, y_pred_classes))\n",
        "\n",
        "\n",
        "test_inputs = [X_test_cat[:, i] for i in range(X_test_cat.shape[1])] + [X_test_num]\n",
        "\n",
        "y_pred_probs = model.predict(test_inputs)\n",
        "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "print('\\nClassification report (Keras multiclass):')\n",
        "print(classification_report(y_test_m, y_pred_classes, digits=4))\n",
        "print('\\nConfusion matrix (Keras multiclass):')\n",
        "print(confusion_matrix(y_test_m, y_pred_classes))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e45BQ0xx0kSF",
        "outputId": "ba12eefb-05d0-4873-b8de-626b9b5b938e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1096/1096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step\n",
            "\n",
            "Classification report (Keras multiclass):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6960    0.2175    0.3314       400\n",
            "           1     0.6053    0.1318    0.2165       349\n",
            "           2     0.3778    0.2426    0.2954      2453\n",
            "           3     0.6529    0.8684    0.7454      6679\n",
            "           4     0.8714    0.8293    0.8498      3637\n",
            "           5     0.9952    0.9841    0.9896      8000\n",
            "           6     0.9790    0.9739    0.9765     11200\n",
            "           7     0.9278    0.7350    0.8202      2098\n",
            "           8     0.6447    0.6476    0.6462       227\n",
            "           9     0.5000    0.1154    0.1875        26\n",
            "\n",
            "    accuracy                         0.8559     35069\n",
            "   macro avg     0.7250    0.5746    0.6059     35069\n",
            "weighted avg     0.8549    0.8559    0.8477     35069\n",
            "\n",
            "\n",
            "Confusion matrix (Keras multiclass):\n",
            "[[   87    13    76   216     0     0     8     0     0     0]\n",
            " [    6    46    78   209     2     1     1     0     6     0]\n",
            " [    1     5   595  1780    24    10     1    16    21     0]\n",
            " [   17     6   600  5800   116    19    20    76    22     3]\n",
            " [   11     6    85   274  3016     5   201    13    26     0]\n",
            " [    1     0    41    72     8  7873     0     0     5     0]\n",
            " [    1     0     1    33   248     0 10908     8     1     0]\n",
            " [    1     0    98   451     5     1     0  1542     0     0]\n",
            " [    0     0     1    29    40     0     3     7   147     0]\n",
            " [    0     0     0    19     2     2     0     0     0     3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- TRANSFER LEARNING ARCHITECTURE ---\n",
        "\n",
        "# 1. Get the base input and output from Model 1\n",
        "# We define the \"Base\" as Model 1 excluding the final classification layer\n",
        "# Note: Keras Functional API allows us to graph-traverse.\n",
        "base_output = model.layers[-2].output  # The output of the last Add/Residual block\n",
        "base_inputs = model.inputs             # The original inputs\n",
        "\n",
        "# 2. Freeze the layers from Model 1\n",
        "# This ensures we don't destroy the 0.85 accuracy knowledge while initializing the new layers\n",
        "for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "print(\"\\nBase layers frozen. Adding new trainable head...\")\n",
        "\n",
        "# 3. Add new, deeper 'Head' layers (Model 2 specific)\n",
        "# This is where we try to squeeze out more performance\n",
        "x = layers.Dense(256, activation='swish')(base_output)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dropout(0.4)(x) # High dropout to prevent overfitting on the pre-trained features\n",
        "\n",
        "x = layers.Dense(128, activation='swish')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "\n",
        "# New Output Layer\n",
        "new_outputs = layers.Dense(num_classes, activation='softmax', name='new_output')(x)\n",
        "\n",
        "# 4. Create Model 2\n",
        "model_2 = models.Model(inputs=base_inputs, outputs=new_outputs, name=\"Transfer_Model\")\n",
        "\n",
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FdiH1oUtpL7s",
        "outputId": "6834fbfe-6650-41a2-8feb-4441941530b5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Base layers frozen. Adding new trainable head...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"Transfer_Model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Transfer_Model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_service       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_proto         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_state         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m7\u001b[0m)      │        \u001b[38;5;34m105\u001b[0m │ input_service[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │      \u001b[38;5;34m2,160\u001b[0m │ input_proto[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m5\u001b[0m)      │         \u001b[38;5;34m55\u001b[0m │ input_state[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_num           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m68\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                     │                   │            │ flatten_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                     │                   │            │ input_num[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m17,664\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m65,792\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m65,792\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │                   │            │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m65,792\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m65,792\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │                   │            │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m65,792\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m512\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ new_output (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │      \u001b[38;5;34m1,290\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_service       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_proto         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_state         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">105</span> │ input_service[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,160</span> │ input_proto[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span> │ input_state[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_num           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                     │                   │            │ flatten_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                     │                   │            │ input_num[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">17,664</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │                   │            │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │                   │            │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ new_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m389,786\u001b[0m (1.49 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">389,786</span> (1.49 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m100,746\u001b[0m (393.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">100,746</span> (393.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m289,040\u001b[0m (1.10 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">289,040</span> (1.10 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.compile(\n",
        "    optimizer=tf.keras.optimizers.AdamW(learning_rate=0.001), # Standard LR\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"\\n--- Phase 1: Training New Head (Base Frozen) ---\")\n",
        "history_phase1 = model_2.fit(\n",
        "    train_inputs,\n",
        "    y_train_m,\n",
        "    epochs=30,  # Quick training to settle the new layers\n",
        "    batch_size=512,\n",
        "    class_weight=class_weights_dict, # KEEP THIS ENABLED\n",
        "    validation_split=0.2,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "    ],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rCnv4gJpbrD",
        "outputId": "1d91e3eb-2489-45c3-eb18-36633e3f86ba"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Phase 1: Training New Head (Base Frozen) ---\n",
            "Epoch 1/30\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 35ms/step - accuracy: 0.6662 - loss: 1.3158 - val_accuracy: 0.7714 - val_loss: 0.5682\n",
            "Epoch 2/30\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - accuracy: 0.7750 - loss: 0.8030 - val_accuracy: 0.7739 - val_loss: 0.5579\n",
            "Epoch 3/30\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - accuracy: 0.7728 - loss: 0.7866 - val_accuracy: 0.7742 - val_loss: 0.5233\n",
            "Epoch 4/30\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - accuracy: 0.7778 - loss: 0.7540 - val_accuracy: 0.7914 - val_loss: 0.5516\n",
            "Epoch 5/30\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - accuracy: 0.7816 - loss: 0.7535 - val_accuracy: 0.7821 - val_loss: 0.5418\n",
            "Epoch 6/30\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - accuracy: 0.7828 - loss: 0.7303 - val_accuracy: 0.8017 - val_loss: 0.5432\n",
            "Epoch 7/30\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.7828 - loss: 0.7085 - val_accuracy: 0.7721 - val_loss: 0.5354\n",
            "Epoch 8/30\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - accuracy: 0.7792 - loss: 0.7254 - val_accuracy: 0.7738 - val_loss: 0.5340\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Unfreeze ALL layers\n",
        "for layer in model_2.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "print(\"\\n--- Phase 2: Fine-Tuning Entire Model (Low LR) ---\")\n",
        "\n",
        "# 2. Compile with a VERY LOW learning rate (1/10th or 1/100th of original)\n",
        "# If LR is too high here, you will destroy the pre-trained weights (Catastrophic Forgetting)\n",
        "model_2.compile(\n",
        "    optimizer=tf.keras.optimizers.AdamW(learning_rate=1e-5), # 0.00001\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 3. Train longer\n",
        "history_phase2 = model_2.fit(\n",
        "    train_inputs,\n",
        "    y_train_m,\n",
        "    epochs=100,\n",
        "    batch_size=512,\n",
        "    # class_weight=class_weights_dict,\n",
        "    class_weight=None,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[\n",
        "        # Longer patience here because improvement is slow and steady\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True),\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
        "    ],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OBjoYg1qDOl",
        "outputId": "2d85f276-7053-456e-bfbb-bd5569a4a804"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Phase 2: Fine-Tuning Entire Model (Low LR) ---\n",
            "Epoch 1/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 70ms/step - accuracy: 0.7991 - loss: 0.5277 - val_accuracy: 0.8402 - val_loss: 0.4186 - learning_rate: 1.0000e-05\n",
            "Epoch 2/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 73ms/step - accuracy: 0.8384 - loss: 0.4389 - val_accuracy: 0.8554 - val_loss: 0.3931 - learning_rate: 1.0000e-05\n",
            "Epoch 3/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 66ms/step - accuracy: 0.8450 - loss: 0.4231 - val_accuracy: 0.8560 - val_loss: 0.3865 - learning_rate: 1.0000e-05\n",
            "Epoch 4/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 67ms/step - accuracy: 0.8466 - loss: 0.4163 - val_accuracy: 0.8557 - val_loss: 0.3842 - learning_rate: 1.0000e-05\n",
            "Epoch 5/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 70ms/step - accuracy: 0.8467 - loss: 0.4170 - val_accuracy: 0.8560 - val_loss: 0.3831 - learning_rate: 1.0000e-05\n",
            "Epoch 6/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 72ms/step - accuracy: 0.8462 - loss: 0.4100 - val_accuracy: 0.8563 - val_loss: 0.3817 - learning_rate: 1.0000e-05\n",
            "Epoch 7/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 68ms/step - accuracy: 0.8473 - loss: 0.4130 - val_accuracy: 0.8569 - val_loss: 0.3806 - learning_rate: 1.0000e-05\n",
            "Epoch 8/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 76ms/step - accuracy: 0.8468 - loss: 0.4101 - val_accuracy: 0.8565 - val_loss: 0.3804 - learning_rate: 1.0000e-05\n",
            "Epoch 9/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 67ms/step - accuracy: 0.8476 - loss: 0.4048 - val_accuracy: 0.8568 - val_loss: 0.3803 - learning_rate: 1.0000e-05\n",
            "Epoch 10/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 67ms/step - accuracy: 0.8473 - loss: 0.4069 - val_accuracy: 0.8570 - val_loss: 0.3797 - learning_rate: 1.0000e-05\n",
            "Epoch 11/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 67ms/step - accuracy: 0.8494 - loss: 0.4050 - val_accuracy: 0.8574 - val_loss: 0.3796 - learning_rate: 1.0000e-05\n",
            "Epoch 12/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 73ms/step - accuracy: 0.8463 - loss: 0.4095 - val_accuracy: 0.8573 - val_loss: 0.3793 - learning_rate: 1.0000e-05\n",
            "Epoch 13/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 70ms/step - accuracy: 0.8493 - loss: 0.4052 - val_accuracy: 0.8574 - val_loss: 0.3792 - learning_rate: 1.0000e-05\n",
            "Epoch 14/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 69ms/step - accuracy: 0.8489 - loss: 0.4037 - val_accuracy: 0.8574 - val_loss: 0.3789 - learning_rate: 1.0000e-05\n",
            "Epoch 15/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 69ms/step - accuracy: 0.8454 - loss: 0.4055 - val_accuracy: 0.8578 - val_loss: 0.3785 - learning_rate: 1.0000e-05\n",
            "Epoch 16/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 73ms/step - accuracy: 0.8498 - loss: 0.3999 - val_accuracy: 0.8581 - val_loss: 0.3781 - learning_rate: 1.0000e-05\n",
            "Epoch 17/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 67ms/step - accuracy: 0.8496 - loss: 0.4019 - val_accuracy: 0.8580 - val_loss: 0.3778 - learning_rate: 1.0000e-05\n",
            "Epoch 18/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 68ms/step - accuracy: 0.8490 - loss: 0.4022 - val_accuracy: 0.8583 - val_loss: 0.3776 - learning_rate: 1.0000e-05\n",
            "Epoch 19/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 68ms/step - accuracy: 0.8510 - loss: 0.3978 - val_accuracy: 0.8574 - val_loss: 0.3776 - learning_rate: 1.0000e-05\n",
            "Epoch 20/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 72ms/step - accuracy: 0.8493 - loss: 0.4026 - val_accuracy: 0.8579 - val_loss: 0.3773 - learning_rate: 1.0000e-05\n",
            "Epoch 21/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 68ms/step - accuracy: 0.8487 - loss: 0.4023 - val_accuracy: 0.8585 - val_loss: 0.3773 - learning_rate: 1.0000e-05\n",
            "Epoch 22/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 67ms/step - accuracy: 0.8513 - loss: 0.3961 - val_accuracy: 0.8580 - val_loss: 0.3770 - learning_rate: 1.0000e-05\n",
            "Epoch 23/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 68ms/step - accuracy: 0.8518 - loss: 0.3971 - val_accuracy: 0.8580 - val_loss: 0.3772 - learning_rate: 1.0000e-05\n",
            "Epoch 24/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 67ms/step - accuracy: 0.8491 - loss: 0.3968 - val_accuracy: 0.8579 - val_loss: 0.3771 - learning_rate: 1.0000e-05\n",
            "Epoch 25/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 68ms/step - accuracy: 0.8501 - loss: 0.4009 - val_accuracy: 0.8579 - val_loss: 0.3769 - learning_rate: 1.0000e-05\n",
            "Epoch 26/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 70ms/step - accuracy: 0.8527 - loss: 0.3949 - val_accuracy: 0.8586 - val_loss: 0.3764 - learning_rate: 1.0000e-05\n",
            "Epoch 27/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 69ms/step - accuracy: 0.8493 - loss: 0.3970 - val_accuracy: 0.8577 - val_loss: 0.3768 - learning_rate: 1.0000e-05\n",
            "Epoch 28/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 68ms/step - accuracy: 0.8513 - loss: 0.3972 - val_accuracy: 0.8579 - val_loss: 0.3766 - learning_rate: 1.0000e-05\n",
            "Epoch 29/100\n",
            "\u001b[1m219/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.8508 - loss: 0.3984\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 73ms/step - accuracy: 0.8508 - loss: 0.3984 - val_accuracy: 0.8581 - val_loss: 0.3769 - learning_rate: 1.0000e-05\n",
            "Epoch 30/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 70ms/step - accuracy: 0.8517 - loss: 0.3941 - val_accuracy: 0.8580 - val_loss: 0.3763 - learning_rate: 5.0000e-06\n",
            "Epoch 31/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 68ms/step - accuracy: 0.8524 - loss: 0.3952 - val_accuracy: 0.8582 - val_loss: 0.3765 - learning_rate: 5.0000e-06\n",
            "Epoch 32/100\n",
            "\u001b[1m219/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.8530 - loss: 0.3917\n",
            "Epoch 32: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 67ms/step - accuracy: 0.8529 - loss: 0.3917 - val_accuracy: 0.8583 - val_loss: 0.3764 - learning_rate: 5.0000e-06\n",
            "Epoch 33/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 67ms/step - accuracy: 0.8533 - loss: 0.3940 - val_accuracy: 0.8585 - val_loss: 0.3763 - learning_rate: 2.5000e-06\n",
            "Epoch 34/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 68ms/step - accuracy: 0.8520 - loss: 0.3970 - val_accuracy: 0.8583 - val_loss: 0.3761 - learning_rate: 2.5000e-06\n",
            "Epoch 35/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 79ms/step - accuracy: 0.8512 - loss: 0.3918 - val_accuracy: 0.8580 - val_loss: 0.3762 - learning_rate: 2.5000e-06\n",
            "Epoch 36/100\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 68ms/step - accuracy: 0.8523 - loss: 0.3927 - val_accuracy: 0.8579 - val_loss: 0.3762 - learning_rate: 2.5000e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this to see the REAL performance .................. REMOVED BECAUSE I WANT TO ADD XGBoost\n",
        "# y_pred_probs = model_2.predict(test_inputs)\n",
        "# y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# print(classification_report(y_test_m, y_pred_classes, digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdrPnuT5siSA",
        "outputId": "30648a8d-ef36-4374-ad06-f5a1857c6d0a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1096/1096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7179    0.2100    0.3250       400\n",
            "           1     0.5753    0.1203    0.1991       349\n",
            "           2     0.3835    0.2556    0.3068      2453\n",
            "           3     0.6555    0.8639    0.7454      6679\n",
            "           4     0.8599    0.8350    0.8473      3637\n",
            "           5     0.9960    0.9840    0.9899      8000\n",
            "           6     0.9807    0.9720    0.9763     11200\n",
            "           7     0.9214    0.7431    0.8227      2098\n",
            "           8     0.6777    0.6300    0.6530       227\n",
            "           9     1.0000    0.1154    0.2069        26\n",
            "\n",
            "    accuracy                         0.8561     35069\n",
            "   macro avg     0.7768    0.5729    0.6072     35069\n",
            "weighted avg     0.8554    0.8561    0.8482     35069\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PASTE THIS AT THE VERY END (After Phase 2 Training is done)\n",
        "# This replaces the old \"model_2.predict\" section\n",
        "# =============================================================================\n",
        "\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print('\\n================ BUILDING HYBRID ENSEMBLE ================')\n",
        "\n",
        "# 1. Prepare Data for XGBoost (It needs flat arrays, not the list the NN uses)\n",
        "# We combine the Ordinal Categories and the Scaled Numerics side-by-side\n",
        "X_train_flat = np.hstack((X_train_cat, X_train_num))\n",
        "X_test_flat = np.hstack((X_test_cat, X_test_num))\n",
        "\n",
        "print(f\"XGBoost Input Shape: {X_train_flat.shape}\")\n",
        "\n",
        "# 2. Train XGBoost (The \"Sharp\" Learner)\n",
        "# This usually takes less than 1 minute\n",
        "clf_xgb = xgb.XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=10,\n",
        "    objective='multi:softprob',\n",
        "    num_class=num_classes,\n",
        "    tree_method='hist',        # optimized for speed\n",
        "    eval_metric='mlogloss',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Training XGBoost helper model...\")\n",
        "clf_xgb.fit(X_train_flat, y_train_m)\n",
        "print(\"Done.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqoVvtEV4JIz",
        "outputId": "7c12e0b6-e0a8-4722-f512-a465c4ada877"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ BUILDING HYBRID ENSEMBLE ================\n",
            "XGBoost Input Shape: (140272, 43)\n",
            "Training XGBoost helper model...\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Get Predictions from BOTH models\n",
        "print(\"Generating ensemble predictions...\")\n",
        "\n",
        "# # A. Neural Net Probabilities (from your transfer learning model)\n",
        "# # Note: We use the list inputs 'test_inputs' here\n",
        "# probs_nn = model_2.predict(test_inputs, verbose=0)\n",
        "\n",
        "# # B. XGBoost Probabilities\n",
        "# # Note: We use the flat inputs 'X_test_flat' here\n",
        "# probs_xgb = clf_xgb.predict_proba(X_test_flat)\n",
        "\n",
        "# # 4. Average them (Ensemble)\n",
        "# # This cancels out errors: if NN is confused, XGB might be sure, and vice versa.\n",
        "# probs_ensemble = (probs_nn + probs_xgb) / 2\n",
        "\n",
        "# # 5. Convert to Class Labels\n",
        "# y_pred_ensemble = np.argmax(probs_ensemble, axis=1)\n",
        "\n",
        "# # 6. Final Evaluation\n",
        "# print('\\n================ ENSEMBLE CLASSIFICATION REPORT ================\\n')\n",
        "# print(classification_report(y_test_m, y_pred_ensemble, digits=4))\n",
        "\n",
        "# print('\\nConfusion Matrix (Ensemble):')\n",
        "# print(confusion_matrix(y_test_m, y_pred_ensemble))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------------------------------------\n",
        "# This is a great result! You achieved 86.87% Accuracy, which is higher than both the original Neural Network (~84%) and the Transfer Learning attempt (~85.6%).\n",
        "# However, the Confusion Matrix reveals exactly where your remaining potential is hiding:\n",
        "# The Problem: Look at Row 2 (Class 2). The model predicted it correctly only 630 times, but confused it as Class 3 a massive 1,758 times.\n",
        "# The Reason: Class 3 is a dominant class (6,679 samples). The model learned that \"when in doubt between 2 and 3, guess 3\" because it's statistically safer.\n",
        "# To squeeze out the final performance (approaching 0.88+) and fix the Recall/F1 for Class 2, we can apply a Surgical Probability Adjustment to the ensemble. We will slightly punish Class 3 to force the model to pick Class 2 when it's uncertain\n",
        "\n",
        "\n",
        "# # 4. Smart Ensemble (Weighted Average + Penalties)\n",
        "# # We give XGBoost slightly more weight (0.6) because trees are sharper at boundaries\n",
        "# # We give the Neural Net slightly less weight (0.4)\n",
        "# probs_ensemble = (0.4 * probs_nn) + (0.6 * probs_xgb)\n",
        "\n",
        "# # --- SURGICAL FIX FOR CLASS 2 vs CLASS 3 ---\n",
        "# # The matrix shows Class 3 is \"eating\" Class 2 predictions.\n",
        "# # We slightly lower the confidence of Class 3 to stop it from bullying Class 2.\n",
        "# # This forces the model to choose the \"second best\" option (Class 2) when it's unsure.\n",
        "\n",
        "# probs_ensemble[:, 3] = probs_ensemble[:, 3] * 0.85  # Dampen Class 3 by 15%\n",
        "\n",
        "# # Re-normalize probabilities (optional, but good practice)\n",
        "# probs_ensemble = probs_ensemble / probs_ensemble.sum(axis=1, keepdims=True)\n",
        "\n",
        "# # 5. Convert to Class Labels\n",
        "# y_pred_ensemble = np.argmax(probs_ensemble, axis=1)\n",
        "\n",
        "# # 6. Final Evaluation\n",
        "# print('\\n================ TUNED ENSEMBLE REPORT ================\\n')\n",
        "# print(classification_report(y_test_m, y_pred_ensemble, digits=4))\n",
        "\n",
        "# print('\\nConfusion Matrix (Tuned):')\n",
        "# print(confusion_matrix(y_test_m, y_pred_ensemble))\n",
        "\n",
        "\n",
        "# DIDN'T WORK: ----------------  broke Class 3. The model started panic-dumping valid Class 3 traffic into Class 2 (1,097 errors), which lowered  overall accuracy\n",
        "# From 86.87% to 86.68%\n",
        "\n",
        "\n",
        "#--------------------------------------------------------------------------------------------------------------\n",
        "# Instead of guessing 0.4 vs 0.6 or hacking the probabilities, let's run a quick loop to mathematically\n",
        "# find the exact perfect mix of the Neural Network and XGBoost that maximizes your score.\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "print('\\n================ OPTIMIZING ENSEMBLE WEIGHTS ================')\n",
        "\n",
        "# 1. Get raw probabilities (no manual hacks)\n",
        "probs_nn = model_2.predict(test_inputs, verbose=0)\n",
        "probs_xgb = clf_xgb.predict_proba(X_test_flat)\n",
        "\n",
        "best_acc = 0.0\n",
        "best_w = 0.0\n",
        "\n",
        "# 2. Grid Search for the perfect weight\n",
        "# We test combining them: (w * NN) + ((1-w) * XGB)\n",
        "for w in np.arange(0.0, 1.01, 0.05):\n",
        "    # Calculate weighted average\n",
        "    curr_probs = (w * probs_nn) + ((1 - w) * probs_xgb)\n",
        "    curr_preds = np.argmax(curr_probs, axis=1)\n",
        "\n",
        "    # Check accuracy\n",
        "    acc = accuracy_score(y_test_m, curr_preds)\n",
        "\n",
        "    # Print progress (optional)\n",
        "    # print(f\"Weight NN: {w:.2f} | XGB: {1-w:.2f} -> Accuracy: {acc:.4f}\")\n",
        "\n",
        "    if acc > best_acc:\n",
        "        best_acc = acc\n",
        "        best_w = w\n",
        "\n",
        "print(f\"\\nBEST FOUND -> NN Weight: {best_w:.2f} | XGB Weight: {1-best_w:.2f}\")\n",
        "print(f\"BEST ACCURACY: {best_acc:.4f}\")\n",
        "\n",
        "# 3. Generate Final Report using the BEST weights\n",
        "final_probs = (best_w * probs_nn) + ((1 - best_w) * probs_xgb)\n",
        "final_preds = np.argmax(final_probs, axis=1)\n",
        "\n",
        "print('\\n================ FINAL OPTIMIZED REPORT ================\\n')\n",
        "print(classification_report(y_test_m, final_preds, digits=4))\n",
        "print('\\nConfusion Matrix:')\n",
        "print(confusion_matrix(y_test_m, final_preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khcskKfv4RLN",
        "outputId": "08f51488-d671-4465-c91b-d94aefda4733"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating ensemble predictions...\n",
            "\n",
            "================ OPTIMIZING ENSEMBLE WEIGHTS ================\n",
            "\n",
            "BEST FOUND -> NN Weight: 0.10 | XGB Weight: 0.90\n",
            "BEST ACCURACY: 0.8722\n",
            "\n",
            "================ FINAL OPTIMIZED REPORT ================\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7431    0.2025    0.3183       400\n",
            "           1     0.7714    0.1547    0.2578       349\n",
            "           2     0.4069    0.2735    0.3272      2453\n",
            "           3     0.6680    0.8825    0.7604      6679\n",
            "           4     0.9393    0.8719    0.9043      3637\n",
            "           5     0.9979    0.9862    0.9920      8000\n",
            "           6     0.9904    0.9891    0.9898     11200\n",
            "           7     0.9232    0.7445    0.8243      2098\n",
            "           8     0.7314    0.7797    0.7548       227\n",
            "           9     0.6250    0.3846    0.4762        26\n",
            "\n",
            "    accuracy                         0.8722     35069\n",
            "   macro avg     0.7797    0.6269    0.6605     35069\n",
            "weighted avg     0.8736    0.8722    0.8646     35069\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[   81    14    81   215     1     0     8     0     0     0]\n",
            " [   12    54    73   197     4     2     1     2     4     0]\n",
            " [    3     0   671  1720    18     7     0    15    19     0]\n",
            " [    6     0   569  5894    70     7    11   100    17     5]\n",
            " [    6     2    86   268  3171     0    83     2    19     0]\n",
            " [    0     0    49    53     5  7890     0     0     3     0]\n",
            " [    0     0     5    25    83     0 11078     6     2     1]\n",
            " [    1     0   114   415     4     0     1  1562     1     0]\n",
            " [    0     0     1    24    18     0     3     4   177     0]\n",
            " [    0     0     0    12     2     1     0     1     0    10]]\n"
          ]
        }
      ]
    }
  ]
}